#	ax+b를 계산하시오. (numpy, numba.jit, parallel, cuda 이용 후 비교)

* 고찰  

  >* 1번 문항에 대해 4가지 계산방법(numpy, numba.jit, parallel, cuda)을 이용했으며 각각의 계산방법에 따른 속도를 측정해 비교해 보았다.  
  >* 0부터 10까지 100개의 구간으로 나눈 경우와 100000000개의 구간으로 나눈 경우로 나누어 실험했다.  
  >* (y와 w 변수를 사용하지 않아도 되지만 코드를 한곳에 모아두어 보기 쉽게 하려고 사용했다.)

* 계산방법
	>* Numpy : 파이썬 자체 알고리즘으로 구동함.  
	>* Numba.jit : 파이썬 코드를 C언어로 컴파일 된 코드와 같은 속도로 작동할 수 있게 함  
	>* Parallel : CPU의 모든 코어를 활용하여 연산할 수 있게 해주는 코드  
	>* Cuda : GPU를 활용해 병렬 가속하는 코드  

![image](https://user-images.githubusercontent.com/83944915/118293545-b70d2f00-b514-11eb-9ae1-fba4340d6f22.png)
![image](https://user-images.githubusercontent.com/83944915/118293556-ba081f80-b514-11eb-9b33-71198e99130b.png)
![image](https://user-images.githubusercontent.com/83944915/118293478-a957a980-b514-11eb-9abe-2f3f470df01a.png)

 
 

  > 첫번째로, X를 0부터 10까지 100개의 구간으로 나눴을 때 4가지 방법에 대해 계산해보았다.  
  계산 속도는 Numba.jit > Numpy > Parallel > Cuda 순으로 빨랐다.  
  계산에 사용된 함수가 y=2x+3인 간단한 형태이며 100개의 구간(작은 구간)만을 고려하기 때문에 파이썬 자체 코드만으로도 충분히 빠른 계산속도를 가지게 된 것으로 보인다.  
  Numba.jit의 경우 C언어와 같은 컴파일 속도를 가지게 해주는 것으로서 위의 경우를 보았을 때 Python 자체 알고리즘에서 컴파일하는 것보다 훨씬 더 빠른 계산속도를 나타냈다.  
  따라서 Numba.jit가 Numpy보다 더 효율적인 계산방법이다.  
  Parallel의 경우 계산이 단순하고 입력 데이터가 작아 CPU 병렬연산을 하지 않아도 Python 자체에서 충분한 계산속도를 얻어낼 수 있어서 Numba.jit와 Numpy보다 느린 계산속도 결과를 얻게 된 것 같다.  
  Cuda의 경우 입력 데이터가 클수록 계산속도에 이점을 가지고 데이터를 CPU에서 GPU로 GPU에서 CPU로 주고받는 특징을 가진다.  
  위의 경우 입력 데이터가 충분히 크지 않고 계산이 매우 간단해 CPU에서 수행하는 것이 GPU로 데이터를 주고받는 것보다 빠르게 수행되기 때문에 계산시간이 가장 느린 결과를 얻었다.

![image](https://user-images.githubusercontent.com/83944915/118294314-8f6a9680-b515-11eb-9abe-bcfcb652675d.png)

  > 두번째로, X를 0부터 10까지 100000000개의 구간으로 나눴을 때 4가지 방법에 대해 계산해보았다.  
  계산 속도는 Cuda > Parallel > Numba.jit > Numpy 순으로 빨랐다.  
  계산에 사용된 함수가 y=2x+3인 간단한 형태이지만 100000000개의 구간(큰 구간)을 고려하기 때문에 파이썬 자체 코드만으로 빠른 계산을 하기 어렵다.  
  이때 사용되는 것이 병렬연산을 통한 가속화이다. Parallel의 경우 주어진 입력 데이터가 커서 CPU 병렬연산의 이점을 살려 빠른 계산속도를 얻어낸 것으로 보인다.  
  이를 통해서 CUDA 다음으로 빠른 속도를 얻게 된 것 같다. Numba.jit의 경우 C언어와 같은 컴파일 속도를 가지게 해주어 Numpy보다는 빠른 속도를 보여주지만 큰 차이는 없는 결과를 보여준다.  
  Numba가 실행되어 가속화되었지만 입력 데이터가 크기 때문에 계산 시간이 늘어난 것으로 보인다. Cuda의 경우 입력 데이터가 클수록 계산속도에 이점을 가진다.  
  위의 경우 입력 데이터가 충분히 크기 때문에 CPU와 GPU간 데이터 교환 속도의 단점을 상쇄하는 계산속도를 가진다.  
  따라서 입력데이터가 클수록 Cuda를 통한 계산이 속도면에서 이점을 보인다.


# Numba를 사용하여 간단한 코드를 만드시오. (Numba를 사용하기 전, jit, parallel, cuda를 모두 사용하여 결과를 비교하시오.)

 ![image](https://user-images.githubusercontent.com/83944915/118294436-ad37fb80-b515-11eb-910f-c735f89c542c.png)


 >* 매우 복잡한 계산식을 풀 때 각 방법의 계산시간이 궁금하여 위와 같은 계산식을 사용하였고 x, y, z 3변수에 대한 방정식을 100000000구간으로 나누어서 푸는 코드를 만들었다.

  ![image](https://user-images.githubusercontent.com/83944915/118294456-b1fcaf80-b515-11eb-87e7-36ce1e7da388.png)
![image](https://user-images.githubusercontent.com/83944915/118294468-b5903680-b515-11eb-9c73-ee2fb2850ccd.png)

> 마지막으로, X를 0부터 10까지 100000000개의 구간으로 나눴을 때 4가지 방법에 대해 계산해보았다. 계산 속도는 Cuda > Parallel > Numba.jit > Numpy 순으로 빨랐다. 계산에 사용된 함수가 복잡해지자 Python 자체 컴파일을 통해 계산되는 numpy의 경우 굉장히 느린 계산 속도를 나타냈다. 이를 보완하기 위해 C언어의 컴파일러와 같은 방식으로 동작하는 Numba.jit 같은 경우 두번째 경우와는 다르게 Numpy와 큰 폭의 계산속도 차이를 보여주었다. 이는 입력데이터가 작고 계산식이 간단할수록 Numpy와 Numba.jit의 계산속도 차이가 작지만 입력데이터가 커지고 계산식이 복잡해질수록 Numba.jit의 계산속도가 훨씬 빨라진다는 것을 의미한다. 하지만 단순연산으로는 계산속도가 빨라지는데 한계가 있다. 이때 사용되는 것이 병렬연산을 통한 가속화이다. Parallel의 경우 주어진 입력 데이터가 커서 CPU 병렬연산의 이점을 살려 빠른 계산속도를 얻어낸 것으로 보인다. 이를 통해서 CUDA 다음으로 빠른 속도를 얻게 된 것 같다. CUDA의 경우 입력 데이터가 클수록 계산속도에 이점을 가진다. 위의 경우 계산식이 복잡하고 입력 데이터가 충분히 크기 때문에 CPU와 GPU간 데이터 교환 속도의 단점을 상쇄하는 계산속도를 가진다. 따라서 계산식이 복잡해지고 입력데이터가 커질수록 CUDA를 통한 계산이 속도면에서 이점을 보인다.

*	결론
> 지금까지 총 세가지 계산식을 4가지 방법으로 계산해보는 실험을 하였다. 결과적으로 입력데이터의 양과 계산식의 복잡한 정도에 따라 계산하는 방법의 계산속도에 차이를 보였다. Numpy의 경우 모든 면에서 Numba.jit 보다 느린 계산속도를 보였고 계산식이 간단하고 입력데이터 양이 작을수록 Numba.jit와 Numpy의 계산속도가 빨랐다. 반대로 계산식이 복잡하고 입력데이터 양이 많을수록 CUDA와 Parallel 방법의 계산속도가 빠른 것을 확인할 수 있었다. 따라서 각 상황에 맞게 계산이 복잡한 경우 CUDA를 간단한 경우 Numba.jit를 사용하는 것이 계산속도면에서 가장 좋은 선택이다.
