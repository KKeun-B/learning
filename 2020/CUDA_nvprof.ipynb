{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CU2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KKeun-B/learning/blob/main/2020/CUDA_nvprof.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30cfEID3_RSw"
      },
      "source": [
        "# CUDA C/C++ 통합 메모리(Unified Memory)와 nvprof을 이용한 가속 애플리케이션 메모리 관리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h62y_-VR_T_t"
      },
      "source": [
        "\n",
        "\n",
        "본 강좌와 다른 CUDA 기초 강좌의 후속 학습 자료로서 강력히 추천하는 [CUDA 베스트 프렉티스 가이드](http://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#memory-optimizations)에서는 **APOD**(**A**sess 평가, **P**arallelize 병렬화, **O**ptimize 최적화, **D**eploy 배포)라고 불리우는 디자인 사이클을 추천하고 있습니다. 간단히 말해서 APOD는 반복적 디자인 프로세스를 규정하는데, 개발자들은 애플리케이션 성능을 가속화하고 코드를 배포하는 데에 있어 점진적 개선 방식을 적용할 수 있습니다. 개발자들이 점점 유능한 CUDA 프로그래머가 되어감에 따라 더 진보한 최적화 기술을 가속화 코드베이스에 적용할 수 있게 됩니다.\n",
        "\n",
        "본 강좌에서는 이러한 반복적 개발 방법론을 이용할 것입니다. 여러분은 **NVIDIA 커맨드라인 프로파일러**를 사용하여 애플리케이션의 성능을 정량적으로(역주: 원문에는 qualitatively이나 quantitative의 오기인 듯) 측정하고, 최적화 기회를 포착하며, 새로운 기법을 배우고 사이클을 반복하기 전에 점진적 개선을 적용하게 될 것입니다. 본 강좌의 핵심은 여러분이 배우고 적용할 다수의 기법들이 CUDA의 **통합 메모리(Unified Memory; UM)**의 동작에 대한 것이라는 점입니다. CUDA 개발자들에게 통합 메모리의 동작 이해는 필수적이며 다른 많은 메모리 관리 기법을 이해하기 위한 발판이 됩니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7HO4ZpT_VPa"
      },
      "source": [
        "---\n",
        "\n",
        "## 선행지식\n",
        "\n",
        "강좌의 이해를 위하여 여러분은 다음 사항을 알고 있어야 합니다.\n",
        "\n",
        "* CPU 함수 호출과 GPU 커널 구동을 포함한 C/C++ 프로그램의 작성, 컴파일, 실행하기\n",
        "* 실행 설정을 이용한 병렬 스레드 계층구조 제어하기\n",
        "* 직렬 반복문을 GPU에서 병렬로 실행하도록 코드 수정하기\n",
        "* 통합 메모리의 할당과 해제\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGdeFq3N_VXd"
      },
      "source": [
        "---\n",
        "\n",
        "## 학습목표\n",
        "\n",
        "강좌를 마치면 여러분은 다음 사항을 수행할 수 있게 될 것입니다.\n",
        "\n",
        "* **NVIDIA 커맨드라인 프로파일러(nvprof)**를 이용하여 가속화 애플리케이션의 성능 프로파일링하기\n",
        "* 실행 설정 최적화를 위한 **스트리밍 멀티프로세서**에 대한 체계적 이해\n",
        "* 페이지 폴트와 데이터 마이그레이션에 관련된 **통합 메모리**의 동작 이해\n",
        "* 페이지 폴트와 데이터 마이그레이션을 감소시켜 성능을 향상시키는 **비동기적 메모리 프리패칭** 사용\n",
        "* 반복적 개발 사이클을 적용하여 애플리케이션 가속화와 배치를 신속히 진행하기\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3Vre6Kk_VaG"
      },
      "source": [
        "---\n",
        "\n",
        "## NVIDIA 프로파일러를 활용한 최적화\n",
        "\n",
        "\n",
        "### 실습: nvprof을 이용하여 애플리케이션 프로파일링 하기\n",
        "\n",
        "가속화 코드 베이스의 최적화 시도가 실제로 성공했는가를 확인하는 방법 중의 하나로서 성능과 관련된 정량적 정보를 프로파일링하는 방법이 있습니다. **`nvprof`**는 이러한 작업을 지원하는 NVIDIA의 커맨드라인 프로파일러입니다. CUDA 툴킷과 함께 배포되는 이것은 가속화 애플리케이션을 프로파일링하는 강력한 도구입니다.\n",
        "\n",
        "`nvprof`를 사용하기는 쉽습니다. 가장 기본적인 사용법은 `nvcc`로 컴파일한 실행 파일의 경로를 전달해 주는 것입니다. `nvprof`는 해당 애플리케이션을 실행한 후 GPU 활동, CUDA API 호출 기록, **통합 메모리(Unified Memory)** 활동 정보 등을 정리하여 출력해 줍니다. 자세한 내용은 강좌를 진행하며 다루도록 하겠습니다.\n",
        "\n",
        "애플리케이션을 가속화하거나 이미 가속화된 애플리케이션을 최적화할 때에 과학적이고 반복적인 접근법을 취하세요. 애플리케이션 변경 후에는 프로파일링을 수행하고, 기록을 남기고, 수정사항이 성능에 미치는 의미를 적으세요. 보다 이른 단계에, 그리고 자주 이러한 관찰을 수행하세요. 작은 노력들이 모여 성능을 획기적으로 향상시키고 출시를 돕는 경우가 많이 있습니다. 빈번한 프로파일링은 특정한 코드 변경이 실제 성능에 어떠한 영향을 미치는가를 여러분에게 가르쳐 줄 것입니다. 이러한 지식은 코드 베이스를 한참 변경한 후에 수행하는 프로파일링으로는 얻을 수 없는 중요한 자산입니다.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xog4F23_Vcx"
      },
      "source": [
        "### 실습: nvprof을 이용하여 애플리케이션 프로파일링 하기\n",
        "\n",
        "[`01-vector-add.cu`](../../../../../edit/tasks/task1/task/02_AC_UM_NVPROF-kr/01-vector-add/01-vector-add.cu)(<---- 소스 파일을 새로운 탭에서 열고 수정하려면 클릭하세요.)는 고속화 벡터합 프로그램입니다. 아래 두 개의 코드 실행 셀을 사용하세요. (`CTRL+ENTER`를 누르면 됩니다.) 첫 번째 코드 실행 셀은 벡터합 프로그램을 컴파일하고 실행합니다. 두 번째 셀은 방금 컴파일한 실행 파일을 `nvprof`을 이용하여 프로파일링합니다.\n",
        "\n",
        "애플리케이션의 프로파일링을 수행한 후, 출력에 나온 정보를 이용하여 아래 질문에 답하세요.\n",
        "\n",
        "* 여기서 호출된 유일한 CUDA 커널의 이름은 무엇인가요?\n",
        "* 커널은 몇 번 실행됐나요?\n",
        "* 커널이 실행되는 데 얼마나 걸렸나요? 시간을 기록해 두세요. 나중에 최적화를 수행하면 얼마나 빨라졌는지 알고 싶으실 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO7vcD4SZ3-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8490d8e3-f9ed-4a67-dae4-68a00e6595b1"
      },
      "source": [
        "%%writefile 01-vector-add.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * Host function to initialize vector elements. This function\n",
        " * simply initializes each element to equal its index in the\n",
        " * vector.\n",
        " */\n",
        "\n",
        "void initWith(float num, float *a, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; ++i)\n",
        "  {\n",
        "    a[i] = num;\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Device kernel stores into `result` the sum of each\n",
        " * same-indexed value of `a` and `b`.\n",
        " */\n",
        "\n",
        "__global__\n",
        "void addVectorsInto(float *result, float *a, float *b, int N)\n",
        "{\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < N; i += stride)\n",
        "  {\n",
        "    result[i] = a[i] + b[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Host function to confirm values in `vector`. This function\n",
        " * assumes all values are the same `target` value.\n",
        " */\n",
        "\n",
        "void checkElementsAre(float target, float *vector, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; i++)\n",
        "  {\n",
        "    if(vector[i] != target)\n",
        "    {\n",
        "      printf(\"FAIL: vector[%d] - %0.0f does not equal %0.0f\\n\", i, vector[i], target);\n",
        "      exit(1);\n",
        "    }\n",
        "  }\n",
        "  printf(\"Success! All values calculated correctly.\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const int N = 2<<24;\n",
        "  size_t size = N * sizeof(float);\n",
        "\n",
        "  float *a;\n",
        "  float *b;\n",
        "  float *c;\n",
        "\n",
        "  cudaMallocManaged(&a, size);\n",
        "  cudaMallocManaged(&b, size);\n",
        "  cudaMallocManaged(&c, size);\n",
        "\n",
        "  initWith(3, a, N);\n",
        "  initWith(4, b, N);\n",
        "  initWith(0, c, N);\n",
        "\n",
        "  size_t threadsPerBlock;\n",
        "  size_t numberOfBlocks;\n",
        "\n",
        "  /*\n",
        "   * nvprof should register performance changes when execution configuration\n",
        "   * is updated.\n",
        "   */\n",
        "\n",
        "  threadsPerBlock = 1;\n",
        "  numberOfBlocks = 1;\n",
        "\n",
        "  cudaError_t addVectorsErr;\n",
        "  cudaError_t asyncErr;\n",
        "\n",
        "  addVectorsInto<<<numberOfBlocks, threadsPerBlock>>>(c, a, b, N);\n",
        "\n",
        "  addVectorsErr = cudaGetLastError();\n",
        "  if(addVectorsErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(addVectorsErr));\n",
        "\n",
        "  asyncErr = cudaDeviceSynchronize();\n",
        "  if(asyncErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(asyncErr));\n",
        "\n",
        "  checkElementsAre(7, c, N);\n",
        "\n",
        "  cudaFree(a);\n",
        "  cudaFree(b);\n",
        "  cudaFree(c);\n",
        "}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing 01-vector-add.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4jJaN69_RSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "738cbfc6-cd54-4299-b8b7-09532222c5b7"
      },
      "source": [
        "!nvcc -o single-thread-vector-add 01-vector-add.cu -run"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success! All values calculated correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1KAqEE-_RS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e120e302-51dc-450a-b166-f0847eed4b04"
      },
      "source": [
        "!nvprof ./single-thread-vector-add"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==140== NVPROF is profiling process 140, command: ./single-thread-vector-add\n",
            "Success! All values calculated correctly.\n",
            "==140== Profiling application: ./single-thread-vector-add\n",
            "==140== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  2.30219s         1  2.30219s  2.30219s  2.30219s  addVectorsInto(float*, float*, float*, int)\n",
            "      API calls:   86.65%  2.30221s         1  2.30221s  2.30221s  2.30221s  cudaDeviceSynchronize\n",
            "                   12.50%  332.14ms         3  110.71ms  24.583us  332.06ms  cudaMallocManaged\n",
            "                    0.82%  21.706ms         3  7.2354ms  6.3716ms  8.6701ms  cudaFree\n",
            "                    0.02%  435.89us         1  435.89us  435.89us  435.89us  cuDeviceTotalMem\n",
            "                    0.01%  172.99us       101  1.7120us     160ns  71.575us  cuDeviceGetAttribute\n",
            "                    0.00%  69.024us         1  69.024us  69.024us  69.024us  cudaLaunchKernel\n",
            "                    0.00%  33.705us         1  33.705us  33.705us  33.705us  cuDeviceGetName\n",
            "                    0.00%  5.8990us         1  5.8990us  5.8990us  5.8990us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.8250us         2     912ns     461ns  1.3640us  cuDeviceGet\n",
            "                    0.00%  1.6710us         3     557ns     274ns  1.0100us  cuDeviceGetCount\n",
            "                    0.00%     440ns         1     440ns     440ns     440ns  cudaGetLastError\n",
            "                    0.00%     340ns         1     340ns     340ns     340ns  cuDeviceGetUuid\n",
            "\n",
            "==140== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "    2304  170.67KB  4.0000KB  0.9961MB  384.0000MB  38.87574ms  Host To Device\n",
            "     768  170.67KB  4.0000KB  0.9961MB  128.0000MB  11.23091ms  Device To Host\n",
            "     768         -         -         -           -  122.8430ms  Gpu page fault groups\n",
            "Total CPU Page faults: 1536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ykx_M9M_RS6"
      },
      "source": [
        "### 실습: 최적화와 프로파일링 하기\n",
        "\n",
        "[`01-vector-add.cu`](../../../../../edit/tasks/task1/task/02_AC_UM_NVPROF-kr/01-vector-add/01-vector-add.cu)가 단일 스레드 블록상의 다수의 스레드에서 실행되도록 실행 설정을 수정하세요. 아래 코드 실행 셀에서 재컴파일하고 `nvprof`을 이용하여 실행 파일을 프로파일링하세요. 프로파일링 출력을 이용하여 커널의 실행 시간을 찾아 보세요. 최적화를 통한 속도 향상이 어느 정도인가요? 결과를  기록하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfpOKriAaVLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ebe5ced-81ea-4b7c-c591-2065d3c8f6e4"
      },
      "source": [
        "%%writefile 01-vector-add.cu\n",
        "\n",
        "\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * Host function to initialize vector elements. This function\n",
        " * simply initializes each element to equal its index in the\n",
        " * vector.\n",
        " */\n",
        "\n",
        "void initWith(float num, float *a, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; ++i)\n",
        "  {\n",
        "    a[i] = num;\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Device kernel stores into `result` the sum of each\n",
        " * same-indexed value of `a` and `b`.\n",
        " */\n",
        "\n",
        "__global__\n",
        "void addVectorsInto(float *result, float *a, float *b, int N)\n",
        "{\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < N; i += stride)\n",
        "  {\n",
        "    result[i] = a[i] + b[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Host function to confirm values in `vector`. This function\n",
        " * assumes all values are the same `target` value.\n",
        " */\n",
        "\n",
        "void checkElementsAre(float target, float *vector, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; i++)\n",
        "  {\n",
        "    if(vector[i] != target)\n",
        "    {\n",
        "      printf(\"FAIL: vector[%d] - %0.0f does not equal %0.0f\\n\", i, vector[i], target);\n",
        "      exit(1);\n",
        "    }\n",
        "  }\n",
        "  printf(\"Success! All values calculated correctly.\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const int N = 2<<24;\n",
        "  size_t size = N * sizeof(float);\n",
        "\n",
        "  float *a;\n",
        "  float *b;\n",
        "  float *c;\n",
        "\n",
        "  cudaMallocManaged(&a, size);\n",
        "  cudaMallocManaged(&b, size);\n",
        "  cudaMallocManaged(&c, size);\n",
        "\n",
        "  initWith(3, a, N);\n",
        "  initWith(4, b, N);\n",
        "  initWith(0, c, N);\n",
        "\n",
        "  size_t threadsPerBlock;\n",
        "  size_t numberOfBlocks;\n",
        "\n",
        "  /*\n",
        "   * nvprof should register performance changes when execution configuration\n",
        "   * is updated.\n",
        "   */\n",
        "\n",
        "  threadsPerBlock = 256;\n",
        "  numberOfBlocks = 128;\n",
        "\n",
        "  cudaError_t addVectorsErr;\n",
        "  cudaError_t asyncErr;\n",
        "\n",
        "  addVectorsInto<<<numberOfBlocks, threadsPerBlock>>>(c, a, b, N);\n",
        "\n",
        "  addVectorsErr = cudaGetLastError();\n",
        "  if(addVectorsErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(addVectorsErr));\n",
        "\n",
        "  asyncErr = cudaDeviceSynchronize();\n",
        "  if(asyncErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(asyncErr));\n",
        "\n",
        "  checkElementsAre(7, c, N);\n",
        "\n",
        "  cudaFree(a);\n",
        "  cudaFree(b);\n",
        "  cudaFree(c);\n",
        "}\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting 01-vector-add.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuRhzAgi_RS7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a1ab03-3dd3-4e78-9474-0a122767803e"
      },
      "source": [
        "!nvcc -o multi-thread-vector-add 01-vector-add.cu -run"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success! All values calculated correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnCW2sYp_RS-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03b4c121-76cf-49fb-ad8e-6ce455b0e6d3"
      },
      "source": [
        "!nvprof ./multi-thread-vector-add"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==190== NVPROF is profiling process 190, command: ./multi-thread-vector-add\n",
            "Success! All values calculated correctly.\n",
            "==190== Profiling application: ./multi-thread-vector-add\n",
            "==190== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  116.31ms         1  116.31ms  116.31ms  116.31ms  addVectorsInto(float*, float*, float*, int)\n",
            "      API calls:   68.73%  306.29ms         3  102.10ms  14.905us  306.22ms  cudaMallocManaged\n",
            "                   26.10%  116.32ms         1  116.32ms  116.32ms  116.32ms  cudaDeviceSynchronize\n",
            "                    5.03%  22.421ms         3  7.4737ms  6.7685ms  8.8603ms  cudaFree\n",
            "                    0.08%  377.78us         1  377.78us  377.78us  377.78us  cuDeviceTotalMem\n",
            "                    0.04%  158.58us       101  1.5700us     134ns  67.454us  cuDeviceGetAttribute\n",
            "                    0.01%  60.642us         1  60.642us  60.642us  60.642us  cudaLaunchKernel\n",
            "                    0.01%  32.991us         1  32.991us  32.991us  32.991us  cuDeviceGetName\n",
            "                    0.00%  6.2150us         1  6.2150us  6.2150us  6.2150us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.8550us         3     618ns     244ns  1.3390us  cuDeviceGetCount\n",
            "                    0.00%  1.4330us         2     716ns     212ns  1.2210us  cuDeviceGet\n",
            "                    0.00%     482ns         1     482ns     482ns     482ns  cudaGetLastError\n",
            "                    0.00%     256ns         1     256ns     256ns     256ns  cuDeviceGetUuid\n",
            "\n",
            "==190== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "    6838  48.553KB  4.0000KB  980.00KB  324.2266MB  45.70454ms  Host To Device\n",
            "     768  170.67KB  4.0000KB  0.9961MB  128.0000MB  11.60547ms  Device To Host\n",
            "     555         -         -         -           -  115.6138ms  Gpu page fault groups\n",
            "Total CPU Page faults: 1536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SkXoVFh_RTC"
      },
      "source": [
        "### 실습: 반복적 최적화 하기\n",
        "\n",
        "본 실습에서 여러분은 몇 차례에 걸쳐 [`01-vector-add.cu`](../../../../../edit/tasks/task1/task/02_AC_UM_NVPROF-kr/01-vector-add/01-vector-add.cu)의 실행 설정을 수정, 프로파일링, 기록함으로써 성능에 미치는 영향을 살펴 볼 것입니다. 아래 가이드라인을 따르세요.\n",
        "\n",
        "* 실행 설정을 업데이트할 3~5 가지 방법을 나열하되, 다양한 범위의 그리드 및 블록 크기 조합을 사용하세요.\n",
        "* [`01-vector-add.cu`](../../../../../edit/tasks/task1/task/02_AC_UM_NVPROF-kr/01-vector-add/01-vector-add.cu)를 수정하여 나열된 방법들을 하나씩 시도하세요.\n",
        "* 아래 셀을 이용하여 컴파일과 프로파일링을 수행하세요.\n",
        "* 프로파일링 출력에 주어진 실행 시간을 기록하세요.\n",
        "* 나열된 방법들 각각에 대한 수정/프로파일/기록 사이클을 수행하세요.\n",
        "\n",
        "어느 실행 설정이 가장 빠른 결과를 보였나요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPWPnoB6aiXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12589369-cd14-47f0-bac8-48e4b64d590c"
      },
      "source": [
        "%%writefile 01-vector-add.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * Host function to initialize vector elements. This function\n",
        " * simply initializes each element to equal its index in the\n",
        " * vector.\n",
        " */\n",
        "\n",
        "void initWith(float num, float *a, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; ++i)\n",
        "  {\n",
        "    a[i] = num;\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Device kernel stores into `result` the sum of each\n",
        " * same-indexed value of `a` and `b`.\n",
        " */\n",
        "\n",
        "__global__\n",
        "void addVectorsInto(float *result, float *a, float *b, int N)\n",
        "{\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < N; i += stride)\n",
        "  {\n",
        "    result[i] = a[i] + b[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Host function to confirm values in `vector`. This function\n",
        " * assumes all values are the same `target` value.\n",
        " */\n",
        "\n",
        "void checkElementsAre(float target, float *vector, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; i++)\n",
        "  {\n",
        "    if(vector[i] != target)\n",
        "    {\n",
        "      printf(\"FAIL: vector[%d] - %0.0f does not equal %0.0f\\n\", i, vector[i], target);\n",
        "      exit(1);\n",
        "    }\n",
        "  }\n",
        "  printf(\"Success! All values calculated correctly.\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const int N = 2<<24;\n",
        "  size_t size = N * sizeof(float);\n",
        "\n",
        "  float *a;\n",
        "  float *b;\n",
        "  float *c;\n",
        "\n",
        "  cudaMallocManaged(&a, size);\n",
        "  cudaMallocManaged(&b, size);\n",
        "  cudaMallocManaged(&c, size);\n",
        "\n",
        "  initWith(3, a, N);\n",
        "  initWith(4, b, N);\n",
        "  initWith(0, c, N);\n",
        "\n",
        "  size_t threadsPerBlock;\n",
        "  size_t numberOfBlocks;\n",
        "\n",
        "  /*\n",
        "   * nvprof should register performance changes when execution configuration\n",
        "   * is updated.\n",
        "   */\n",
        "\n",
        "  threadsPerBlock = 1024;\n",
        "  numberOfBlocks = 256;\n",
        "\n",
        "  cudaError_t addVectorsErr;\n",
        "  cudaError_t asyncErr;\n",
        "\n",
        "  addVectorsInto<<<numberOfBlocks, threadsPerBlock>>>(c, a, b, N);\n",
        "\n",
        "  addVectorsErr = cudaGetLastError();\n",
        "  if(addVectorsErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(addVectorsErr));\n",
        "\n",
        "  asyncErr = cudaDeviceSynchronize();\n",
        "  if(asyncErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(asyncErr));\n",
        "\n",
        "  checkElementsAre(7, c, N);\n",
        "\n",
        "  cudaFree(a);\n",
        "  cudaFree(b);\n",
        "  cudaFree(c);\n",
        "}\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting 01-vector-add.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5q74gJB_RTD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212ab0f2-27eb-4c0c-f57e-173635b1afff"
      },
      "source": [
        "!nvcc -o iteratively-optimized-vector-add 01-vector-add.cu -run"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success! All values calculated correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIfWJW2h_RTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc22a02-27ca-4a30-ce72-d85aeab3b992"
      },
      "source": [
        "!nvprof ./iteratively-optimized-vector-add"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==240== NVPROF is profiling process 240, command: ./iteratively-optimized-vector-add\n",
            "Success! All values calculated correctly.\n",
            "==240== Profiling application: ./iteratively-optimized-vector-add\n",
            "==240== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  124.99ms         1  124.99ms  124.99ms  124.99ms  addVectorsInto(float*, float*, float*, int)\n",
            "      API calls:   68.18%  316.25ms         3  105.42ms  14.910us  316.17ms  cudaMallocManaged\n",
            "                   26.95%  125.00ms         1  125.00ms  125.00ms  125.00ms  cudaDeviceSynchronize\n",
            "                    4.73%  21.942ms         3  7.3139ms  6.6601ms  8.5521ms  cudaFree\n",
            "                    0.09%  400.60us         1  400.60us  400.60us  400.60us  cuDeviceTotalMem\n",
            "                    0.04%  165.68us       101  1.6400us     152ns  71.189us  cuDeviceGetAttribute\n",
            "                    0.01%  58.775us         1  58.775us  58.775us  58.775us  cudaLaunchKernel\n",
            "                    0.01%  32.399us         1  32.399us  32.399us  32.399us  cuDeviceGetName\n",
            "                    0.00%  7.6190us         1  7.6190us  7.6190us  7.6190us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.6090us         3     869ns     217ns  1.9120us  cuDeviceGetCount\n",
            "                    0.00%  1.4930us         2     746ns     329ns  1.1640us  cuDeviceGet\n",
            "                    0.00%     302ns         1     302ns     302ns     302ns  cudaGetLastError\n",
            "                    0.00%     297ns         1     297ns     297ns     297ns  cuDeviceGetUuid\n",
            "\n",
            "==240== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "    6988  23.017KB  4.0000KB  252.00KB  157.0742MB  32.11568ms  Host To Device\n",
            "     768  170.67KB  4.0000KB  0.9961MB  128.0000MB  11.55510ms  Device To Host\n",
            "     510         -         -         -           -  123.4393ms  Gpu page fault groups\n",
            "Total CPU Page faults: 1536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBJZ0mr0_RTK"
      },
      "source": [
        "---\n",
        "\n",
        "## 스트리밍 멀티프로세서와 디바이스 질의하기\n",
        "\n",
        "본 섹션에서는 GPU 하드웨어의 특정 기능을 이해하고 이것을 최적화에 활용하는 법을 살펴 봅니다. 먼저 **스트리밍 멀티프로세서**를 살펴 보고 앞에서 작업한 가속 벡터합 프로그램을 좀 더 최적화해 봅니다.\n",
        "\n",
        "다음 슬라이드는 앞으로 공부할 내용을 개략적인 수준에서 시각적으로 보여줍니다. 주제를 보다 상세히 다루기에 앞서 슬라이드를 클릭하시면서 살펴 보세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcRZmRBe_RTL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "41dc31e9-f60f-415d-874f-c5a586361219"
      },
      "source": [
        "%%HTML\n",
        "\n",
        "<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vRByDOlhmGKNY9IgFonAhE-uM0NAPdZGo8v8vlBBPqRB7RDx-E5g0OnGOpC2VoO-eWFhZBWv5yCtGfk/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vRByDOlhmGKNY9IgFonAhE-uM0NAPdZGo8v8vlBBPqRB7RDx-E5g0OnGOpC2VoO-eWFhZBWv5yCtGfk/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Civl39l_RTQ"
      },
      "source": [
        "---\n",
        "### 스트리밍 멀티프로세서와 워프\n",
        "\n",
        "CUDA 애플리케이션을 실행하는 GPU는 **스트리밍 멀티프로세서(streaming multiprocessor; SM)**라는 프로세싱 유닛을 가지고 있습니다. 최대한 많은 수의 병렬처리를 위하여 GPU에 있는 *SM 숫자의 배수로 이루어진 블록수를 그리드의 크기로 선택*함으로써 성능 이득을 얻을 수 있습니다.\n",
        "\n",
        "SM은 하나의 블록 안에 있는 32 개의 스레드를 하나의 그룹처럼 다루어 스레드 생성, 관리, 스케쥴링, 실행을 합니다. 이러한 32 개의 스레드로 이루어진 그룹을 **워프([warp](https://en.wikipedia.org/wiki/Thread_block_(CUDA_programming)#Warps))**라고 합니다. [SM과 warp에 대한 상세 내용](http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#hardware-implementation)은 본 강좌의 범위를 벗어나지만 *32의 배수를 스레드 개수로 갖는 블록 크기를 선택*함으로써 성능 이득을 얻을 수 있다는 것을 기억하는 것은 중요합니다. \n",
        "\n",
        "### 프로그램으로 GPU 디바이스 속성 질의하기\n",
        "\n",
        "GPU 상의 SM 개수는 GPU 모델에 따라 다르기 때문에, 서로 다른 SM 개수를 가진 GPU 간의 프로그램 이식성을 유지하기 위하여 SM 개수는 코드 베이스에 하드코드되어서는 안됩니다. 이 정보는 프로그램으로 얻어내야 합니다.\n",
        "\n",
        "아래 예제는 CUDA C/C++에서, SM 값을 포함하여, 현재 활성화된 GPU의 다양한 속성을 알아내는 데 사용되는 C 구조체를 얻는 방법을 보여줍니다. \n",
        "\n",
        "```cpp\n",
        "int deviceId;\n",
        "cudaGetDevice(&deviceId);                  // `deviceId` now points to the id of the currently active GPU.\n",
        "\n",
        "cudaDeviceProp props;\n",
        "cudaGetDeviceProperties(&props, deviceId); // `props` now has many useful properties about\n",
        "                                           // the active GPU device.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JufkGBzBGfO"
      },
      "source": [
        "### 실습: 디바이스 질의하기\n",
        "\n",
        "[`01-get-device-properties.cu`](../../../../../edit/tasks/task1/task/02_AC_UM_NVPROF-kr/04-device-properties/01-get-device-properties.cu)는 다수의 초기화되지 않은 변수를 포함하고 있기 때문에, 현재 활성화된 GPU의 상세한 속성을 표시해야 하는 부분에서 의미 없는 값을 출력하고 있습니다. \n",
        "\n",
        "[`01-get-device-properties.cu`](../../../../../edit/tasks/task1/task/02_AC_UM_NVPROF-kr/04-device-properties/01-get-device-properties.cu) 코드를 수정하여 소스 코드가 의도했던 바대로 디바이스 속성의 실제값을 출력하도록 만드세요. [CUDA 런타임 문서](http://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html)를 읽어 보시면 실습을 진행하는 데 필요한 도움을 얻을 수 있습니다. 어떻게 해야 할 지 모르는 경우에는 ***(솔루션      : 01-get-device-properties-solution.cu)***을 참고하세요. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7lFHL5ta1B_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "384621db-1cee-4cf8-ff86-9506c78be332"
      },
      "source": [
        "%%writefile 01-get-device-properties.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "int main()\n",
        "{\n",
        "  /*\n",
        "   * Assign values to these variables so that the output string below prints the\n",
        "   * requested properties of the currently active GPU.\n",
        "   */\n",
        "\n",
        "  int deviceId;\n",
        "  cudaGetDevice(&deviceId);\n",
        "  cudaDeviceProp props;\n",
        "  cudaGetDeviceProperties(&props, deviceId); \n",
        "  int computeCapabilityMajor = props.major;\n",
        "  int computeCapabilityMinor = props.minor;\n",
        "  int multiProcessorCount = props.multiProcessorCount;\n",
        "  int warpSize = props.warpSize;\n",
        "\n",
        "  /*\n",
        "   * There should be no need to modify the output string below.\n",
        "   */\n",
        "\n",
        "  printf(\"Device ID: %d\\nNumber of SMs: %d\\nCompute Capability Major: %d\\nCompute Capability Minor: %d\\nWarp Size: %d\\n\", deviceId, multiProcessorCount, computeCapabilityMajor, computeCapabilityMinor, warpSize);\n",
        "}\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing 01-get-device-properties.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53YQ_JP9_RTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7b95e1d-4d62-4def-98dc-175bc1a9237d"
      },
      "source": [
        "!nvcc -o get-device-properties 01-get-device-properties.cu -run"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device ID: 0\n",
            "Number of SMs: 40\n",
            "Compute Capability Major: 7\n",
            "Compute Capability Minor: 5\n",
            "Warp Size: 32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x6FdbCW_RTW"
      },
      "source": [
        "### 실습: SM 숫자에 맞춘 크기의 그리드를 사용한 벡터합 최적화\n",
        "\n",
        "앞에서 배운 SM 개수 질의 기능을 이용하여 [`01-vector-add.cu`](../../../../../edit/tasks/task1/task/02_AC_UM_NVPROF-kr/01-vector-add/01-vector-add.cu)의 `addVectorsInto` 커널을 수정하되, 이를 SM 개수의 배수에 해당하는 블럭을 포함한 그리드로 구동되게 하세요.\n",
        "\n",
        "여러분이 작성하는 코드의 세부 내용에 따라서 수정 사항이 커널 성능 개선을 이룰 수도, 이루지 않을 수도 있습니다. `nvprof`를 이용하여 성능 변화를 정량적으로 측정하고 그 결과를 통해 발견한 사항을 기록하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwNXNMpfbOAJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6423f30-7832-4bd4-d0fc-95dbfa0cc54f"
      },
      "source": [
        "%%writefile 01-vector-add.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * Host function to initialize vector elements. This function\n",
        " * simply initializes each element to equal its index in the\n",
        " * vector.\n",
        " */\n",
        "\n",
        "void initWith(float num, float *a, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; ++i)\n",
        "  {\n",
        "    a[i] = num;\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Device kernel stores into `result` the sum of each\n",
        " * same-indexed value of `a` and `b`.\n",
        " */\n",
        "\n",
        "__global__\n",
        "void addVectorsInto(float *result, float *a, float *b, int N)\n",
        "{\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < N; i += stride)\n",
        "  {\n",
        "    result[i] = a[i] + b[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Host function to confirm values in `vector`. This function\n",
        " * assumes all values are the same `target` value.\n",
        " */\n",
        "\n",
        "void checkElementsAre(float target, float *vector, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; i++)\n",
        "  {\n",
        "    if(vector[i] != target)\n",
        "    {\n",
        "      printf(\"FAIL: vector[%d] - %0.0f does not equal %0.0f\\n\", i, vector[i], target);\n",
        "      exit(1);\n",
        "    }\n",
        "  }\n",
        "  printf(\"Success! All values calculated correctly.\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const int N = 2<<24;\n",
        "  size_t size = N * sizeof(float);\n",
        "\n",
        "  float *a;\n",
        "  float *b;\n",
        "  float *c;\n",
        " \n",
        "  int deviceId;\n",
        "  cudaGetDevice(&deviceId);\n",
        "  cudaDeviceProp props;\n",
        "  cudaGetDeviceProperties(&props, deviceId);\n",
        "  int multiProcessorCount = props.multiProcessorCount;\n",
        "  int warpSize = props.warpSize;\n",
        "\n",
        "  cudaMallocManaged(&a, size);\n",
        "  cudaMallocManaged(&b, size);\n",
        "  cudaMallocManaged(&c, size);\n",
        "\n",
        "  initWith(3, a, N);\n",
        "  initWith(4, b, N);\n",
        "  initWith(0, c, N);\n",
        "\n",
        "  size_t threadsPerBlock;\n",
        "  size_t numberOfBlocks;\n",
        "\n",
        "  /*\n",
        "   * nvprof should register performance changes when execution configuration\n",
        "   * is updated.\n",
        "   */\n",
        "\n",
        "  threadsPerBlock = warpSize*32;\n",
        "  numberOfBlocks = multiProcessorCount*32;\n",
        "\n",
        "  cudaError_t addVectorsErr;\n",
        "  cudaError_t asyncErr;\n",
        "\n",
        "  addVectorsInto<<<numberOfBlocks, threadsPerBlock>>>(c, a, b, N);\n",
        "\n",
        "  addVectorsErr = cudaGetLastError();\n",
        "  if(addVectorsErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(addVectorsErr));\n",
        "\n",
        "  asyncErr = cudaDeviceSynchronize();\n",
        "  if(asyncErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(asyncErr));\n",
        "\n",
        "  checkElementsAre(7, c, N);\n",
        "\n",
        "  cudaFree(a);\n",
        "  cudaFree(b);\n",
        "  cudaFree(c);\n",
        "}\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting 01-vector-add.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0zJk4Gm_RTX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c2b42ba-91f5-4c0d-9cc3-11960c3252bb"
      },
      "source": [
        "!nvcc -o sm-optimized-vector-add 01-vector-add.cu -run"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success! All values calculated correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqupE6Yn_RTa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7474938c-4c1e-431c-a7f8-f401423dcf54"
      },
      "source": [
        "!nvprof ./sm-optimized-vector-add"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==328== NVPROF is profiling process 328, command: ./sm-optimized-vector-add\n",
            "Success! All values calculated correctly.\n",
            "==328== Profiling application: ./sm-optimized-vector-add\n",
            "==328== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  108.88ms         1  108.88ms  108.88ms  108.88ms  addVectorsInto(float*, float*, float*, int)\n",
            "      API calls:   70.26%  311.97ms         3  103.99ms  21.221us  311.89ms  cudaMallocManaged\n",
            "                   24.53%  108.89ms         1  108.89ms  108.89ms  108.89ms  cudaDeviceSynchronize\n",
            "                    5.04%  22.395ms         3  7.4650ms  6.8266ms  8.6679ms  cudaFree\n",
            "                    0.08%  353.67us         1  353.67us  353.67us  353.67us  cuDeviceTotalMem\n",
            "                    0.04%  159.98us       101  1.5830us     132ns  70.387us  cuDeviceGetAttribute\n",
            "                    0.03%  113.79us         1  113.79us  113.79us  113.79us  cudaGetDeviceProperties\n",
            "                    0.01%  60.181us         1  60.181us  60.181us  60.181us  cudaLaunchKernel\n",
            "                    0.01%  31.594us         1  31.594us  31.594us  31.594us  cuDeviceGetName\n",
            "                    0.00%  5.6610us         1  5.6610us  5.6610us  5.6610us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.7110us         1  2.7110us  2.7110us  2.7110us  cudaGetDevice\n",
            "                    0.00%  1.7690us         3     589ns     435ns     878ns  cuDeviceGetCount\n",
            "                    0.00%  1.3230us         2     661ns     255ns  1.0680us  cuDeviceGet\n",
            "                    0.00%     470ns         1     470ns     470ns     470ns  cudaGetLastError\n",
            "                    0.00%     295ns         1     295ns     295ns     295ns  cuDeviceGetUuid\n",
            "\n",
            "==328== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "    4231  51.014KB  4.0000KB  972.00KB  210.7813MB  29.58486ms  Host To Device\n",
            "     766  171.03KB  4.0000KB  0.9961MB  127.9375MB  11.56778ms  Device To Host\n",
            "Total CPU Page faults: 1536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eB2tPlw_RTf"
      },
      "source": [
        "---\n",
        "\n",
        "## 통합 메모리(Unified Memory) 세부 내용\n",
        "\n",
        "여러분은 `cudaMallocManaged` 함수를 이용하여 호스트와 디바이스 코드가 사용할 메모리를 할당해 왔습니다. 지금까지 이 함수가 제공하는 자동 메모리 마이그레이션, 쉬운 프로그래밍과 같은 혜택을 이용해 오면서도 `cudaMallocManaged`가 실제로 할당하는 **통합 메모리(unified memeory; UM)**에 대한 세부 내용은 신경 쓸 필요가 없었습니다. `nvprof`는 가속화 애플리케이션의 UM 관리에 대한 상세한 정보를 제공하는데, 이 정보와 아울러 UM의 작동 원리를 보다 잘 이해하게 된다면 가속 애플리케이션 최적화의 추가적인 기회 얻을 수 있습니다.  \n",
        "\n",
        "다음 슬라이드는 앞으로 공부할 내용을 개략적인 수준에서 시각적으로 보여줍니다. 주제를 보다 상세히 다루기에 앞서 슬라이드를 클릭하시면서 살펴 보세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYxq2B8T_RTg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "9c77f931-e58f-4238-d18a-f6be96f62c3d"
      },
      "source": [
        "%%HTML\n",
        "\n",
        "<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vTasuq4eIe8Xd_G-xL-dD6hbkv48C_8xD4WS1780qnWnidDc5FApS--f86luAU5uM5IlJiiAhBAH4v-/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vTasuq4eIe8Xd_G-xL-dD6hbkv48C_8xD4WS1780qnWnidDc5FApS--f86luAU5uM5IlJiiAhBAH4v-/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"900\" height=\"550\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybH9kfZV_RTk"
      },
      "source": [
        "### 통합 메모리(UM) 마이그레이션\n",
        "\n",
        "UM이 할당될 때, 메모리는 아직 호스트 또는 디바이스에 적재되지 않습니다. 호스트나 디바이스가 그 메모리에 접근하려고 하면 [페이지 폴트](https://en.wikipedia.org/wiki/Page_fault)가 일어나고 이 시점에 호스트와 디바이스는 필요한 데이터를 연속적으로 읽어들여 옵니다. 이것을 메모리 마이그레이션(memory migration)이라고 합니다. 이와 마찬가지로 호스트나 디바이스가 아직 적재되지 않은 메모리에 접근을 시도한다면 페이지 폴트가 일어나고 마이그레이션이 시작됩니다.\n",
        "\n",
        "페이지 폴트와 요청시 마이그레이션은 가속화 애플리케이션 개발을 쉽게 해주어 큰 도움이 됩니다. 특히 애플리케이션이 실제로 실행되어 데이터를 필요로 할 때까지 어느 데이터가 필요한지 알 수 없는 경우가 있는데, 이와 같이 흩어진 데이터를 다루는 경우, 또는 다수의 GPU가 접근하는 데이터와 같은 경우에 있어서 요청시 마이그레이션은 매우 유용합니다.\n",
        "\n",
        "하지만 어떤 데이터가 필요한지 미리 알 수 있는 경우와 큰 연속 메모리 영역이 필요한 경우도 많이 있습니다. 이 경우에는 오히려 페이지 폴트와 요청시 마이그레이션의 오버헤드가 큰 부담이 되므로 이러한 오버헤드 비용은 피하는 것이 좋습니다.\n",
        "\n",
        "본 강좌의 나머지 부분은 요청시 마이그레이션을 이해하고 프로파일러 출력에서 이를 확인하는 것에 대해 할애할 것입니다. 이러한 지식을 통하여 여러분은 오버헤드를 피하는 것이 유리한 경우를 이해하고 대처할 수 있게 될 것입니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1SEmwzGBdeK"
      },
      "source": [
        "### 실습: UM 페이지 폴트 살펴 보기\n",
        "\n",
        "`nvprof`는 대상 애플리케이션의 UM 작동 상황을 출력합니다. 본 실습에서 여러분은 간단한 애플리케이션을 수정해 가면서, 각 수정에 대한 `nvprof`의 UM 출력 부분을 이용하여 UM 데이터 마이그레이션 행동을 살펴볼 것입니다.\n",
        "\n",
        "[`01-page-faults.cu`](../../../../../edit/tasks/task1/task/02_AC_UM_NVPROF-kr/06-unified-memory-page-faults/01-page-faults.cu)은 `hostFunction`과 `gpuKernel`을 포함하는데 이들은 2<<24 개의 원소를 가지는 벡터의 원소값을 1로 초기화하는 역할을 합니다. 아직은 이들 호스트 함수와 디바이스 커널은 사용되지 않습니다. 아래 네 개의 질문에 대하여 여러분이 UM 동작에 대해 배운 것을 기반으로 하여 어떤 종류의 페이지 폴트가 일어날지 가정해 보새요. 다음으로는 [`01-page-faults.cu`](../../../../../edit/tasks/task1/task/02_AC_UM_NVPROF-kr/06-unified-memory-page-faults/01-page-faults.cu)를 수정하되, 앞에서 나온 함수들을 이용하여 여러분의 가정을 검증할 시나리오를 작성하세요.\n",
        "\n",
        "여러분의 가정을 검증하기 위해서 아래 셀을 이용하여 코드를 컴파일하고 프로파일링 하세요. 여러분의 가정과 함께 `nvprof`에서 얻은 결과를 기록하되, CPU와 GPU의 페이지 폴트에 집중하며 네 개의 실험을 수행하세요. 어떻게 해야 할 지 모를 때에는 질문 옆에 있는 솔루션 링크를 참고하세요. \n",
        "\n",
        "* 통합 메모리가 CPU에 의해서만 사용될 때 무슨 일이 일어날까요? ***(솔루션:01-page-faults-solution-cpu-only.cu)***\n",
        "* 통합 메모리가 GPU에 의해서만 사용될 때 무슨 일이 일어날까요? ***(솔루션:02-page-faults-solution-gpu-only.cu)***\n",
        "* 통합 메모리가 CPU에 의해 먼저 사용되고 다음으로 GPU에 의해서 사용될 때 무슨 일이 일어날까요? ***(솔루션:03-page-faults-solution-cpu-then-gpu.cu)***\n",
        "* 통합 메모리가 GPU에 의해 먼저 사용되고 다음으로 CPU에 의해서 사용될 때 무슨 일이 일어날까요? ***(솔루션:04-page-faults-solution-gpu-then-cpu.cu)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XaAdBo9cpjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adffa4a4-61e8-49f7-9d2a-91e2ef216454"
      },
      "source": [
        "%%writefile 01-page-faults.cu\n",
        "\n",
        "__global__\n",
        "void deviceKernel(int *a, int N)\n",
        "{\n",
        "  int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for (int i = idx; i < N; i += stride)\n",
        "  {\n",
        "    a[i] = 1;\n",
        "  }\n",
        "}\n",
        "\n",
        "void hostFunction(int *a, int N)\n",
        "{\n",
        "  for (int i = 0; i < N; ++i)\n",
        "  {\n",
        "    a[i] = 1;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "  int N = 2<<24;\n",
        "  size_t size = N * sizeof(int);\n",
        "  int *a;\n",
        "  cudaMallocManaged(&a, size);\n",
        " \n",
        " // hostFunction(a,N);\n",
        "  hostFunction(a,N);\n",
        "  deviceKernel<<<128,256>>>(a,N);\n",
        "  cudaDeviceSynchronize();\n",
        "  /*\n",
        "   * Conduct experiments to learn more about the behavior of\n",
        "   * `cudaMallocManaged`.\n",
        "   *\n",
        "   * What happens when unified memory is accessed only by the GPU?\n",
        "   * What happens when unified memory is accessed only by the CPU?\n",
        "   * What happens when unified memory is accessed first by the GPU then the CPU?\n",
        "   * What happens when unified memory is accessed first by the CPU then the GPU?\n",
        "   *\n",
        "   * Hypothesize about UM behavior, page faulting specificially, before each\n",
        "   * experiement, and then verify by running `nvprof`.\n",
        "   */\n",
        "\n",
        "  cudaFree(a);\n",
        "}\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing 01-page-faults.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgU_u5CT_RTm"
      },
      "source": [
        "!nvcc  -o page-faults 01-page-faults.cu -run"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faCVxIx__RTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "910edf93-df1a-416b-b908-a65f95bbf763"
      },
      "source": [
        "!nvprof ./page-faults"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==378== NVPROF is profiling process 378, command: ./page-faults\n",
            "==378== Profiling application: ./page-faults\n",
            "==378== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  85.614ms         1  85.614ms  85.614ms  85.614ms  deviceKernel(int*, int)\n",
            "      API calls:   77.72%  324.80ms         1  324.80ms  324.80ms  324.80ms  cudaMallocManaged\n",
            "                   20.49%  85.643ms         1  85.643ms  85.643ms  85.643ms  cudaDeviceSynchronize\n",
            "                    1.63%  6.8052ms         1  6.8052ms  6.8052ms  6.8052ms  cudaFree\n",
            "                    0.09%  392.07us         1  392.07us  392.07us  392.07us  cuDeviceTotalMem\n",
            "                    0.04%  157.16us       101  1.5560us     140ns  66.800us  cuDeviceGetAttribute\n",
            "                    0.01%  54.053us         1  54.053us  54.053us  54.053us  cudaLaunchKernel\n",
            "                    0.01%  29.293us         1  29.293us  29.293us  29.293us  cuDeviceGetName\n",
            "                    0.00%  6.8590us         1  6.8590us  6.8590us  6.8590us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.1450us         3     715ns     289ns  1.3350us  cuDeviceGetCount\n",
            "                    0.00%  1.3350us         2     667ns     218ns  1.1170us  cuDeviceGet\n",
            "                    0.00%     274ns         1     274ns     274ns     274ns  cuDeviceGetUuid\n",
            "\n",
            "==378== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "    4766  27.501KB  4.0000KB  960.00KB  128.0000MB  23.57418ms  Host To Device\n",
            "     854         -         -         -           -  85.33005ms  Gpu page fault groups\n",
            "Total CPU Page faults: 384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLY_f8Hj_RTu"
      },
      "source": [
        "### 실습: 벡터합 프로그렘에서 UM 동작 다시 살펴보기\n",
        "\n",
        "\n",
        "이제 다시 [`01-vector-add.cu`](../../../../../edit/tasks/task1/task/02_AC_UM_NVPROF-kr/01-vector-add/01-vector-add.cu)로 돌아오세요. 현재의 코드 베이스를 살펴 보고 어떤 종류의 페이지 폴트가 일어날지 생각해 보세요. 제일 마지막으로 코드를 수정했을 때의 프로파일링 결과를 살펴 보세요. 과거 출력을 찾아 보기 위해 위로 스크롤하시거나 아래 셀에서 명령을 다시 실행하면 됩니다. 통합 메모리의 프로파일 출력을 살펴 보세요. 현재 코드 베이스의 내용으로부터 프로파일의 페이지 폴트 결과 출력을 스스로 설명할 수 있으시겠어요?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tthpxx50_RTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a21fb76b-a1ef-4d84-c1a5-117f508c4ec8"
      },
      "source": [
        "!nvprof ./sm-optimized-vector-add"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==391== NVPROF is profiling process 391, command: ./sm-optimized-vector-add\n",
            "Success! All values calculated correctly.\n",
            "==391== Profiling application: ./sm-optimized-vector-add\n",
            "==391== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  118.14ms         1  118.14ms  118.14ms  118.14ms  addVectorsInto(float*, float*, float*, int)\n",
            "      API calls:   68.38%  305.94ms         3  101.98ms  14.897us  305.88ms  cudaMallocManaged\n",
            "                   26.41%  118.16ms         1  118.16ms  118.16ms  118.16ms  cudaDeviceSynchronize\n",
            "                    5.03%  22.511ms         3  7.5038ms  6.7355ms  8.7005ms  cudaFree\n",
            "                    0.09%  394.77us         1  394.77us  394.77us  394.77us  cuDeviceTotalMem\n",
            "                    0.03%  150.60us       101  1.4910us     142ns  65.391us  cuDeviceGetAttribute\n",
            "                    0.03%  118.96us         1  118.96us  118.96us  118.96us  cudaGetDeviceProperties\n",
            "                    0.02%  68.035us         1  68.035us  68.035us  68.035us  cudaLaunchKernel\n",
            "                    0.01%  30.050us         1  30.050us  30.050us  30.050us  cuDeviceGetName\n",
            "                    0.00%  7.3430us         1  7.3430us  7.3430us  7.3430us  cudaGetDevice\n",
            "                    0.00%  5.7220us         1  5.7220us  5.7220us  5.7220us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.5080us         3     502ns     266ns     886ns  cuDeviceGetCount\n",
            "                    0.00%  1.0950us         2     547ns     279ns     816ns  cuDeviceGet\n",
            "                    0.00%     535ns         1     535ns     535ns     535ns  cudaGetLastError\n",
            "                    0.00%     246ns         1     246ns     246ns     246ns  cuDeviceGetUuid\n",
            "\n",
            "==391== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "    5056  53.073KB  4.0000KB  0.9883MB  262.0508MB  36.29728ms  Host To Device\n",
            "     766  171.03KB  4.0000KB  0.9961MB  127.9375MB  11.54618ms  Device To Host\n",
            "Total CPU Page faults: 1536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1i9bvFo_RTz"
      },
      "source": [
        "### 실습: 커널에서 벡터 초기화\n",
        "\n",
        "`nvprof`가 얼마 동안 커널을 실행하여 HtoD(Host to Device) 페이지 폴트와 데이터 마이그레이션이 발생하면, 그 페이지 폴트와 마이그레이션 역시 실행 시간에 포함되어 출력됩니다. 이것을 염두하시면서 [`01-vector-add.cu`](../../../../../edit/tasks/task1/task/02_AC_UM_NVPROF-kr/01-vector-add/01-vector-add.cu)의 `initWith` 호스트 함수를 수정하여 CUDA 커널로 만들고, 할당된 벡터를 GPU에서 병렬로 초기화하세요. 수정된 코드를 성공적으로 컴파일하고 실행한 뒤, 프로파일링에 앞서 다음 사항에 대한 가정을 수립해 보세요.\n",
        "\n",
        "* 코드 수정이 UM 페이지 폴트 동작에 어떤 영향을 미칠까요?\n",
        "* 코드 수정이 `addVectorsInto`의 실행 시간에 어떤 영향을 미칠까요?\n",
        "\n",
        "결과를 기록하세요. 어떻게 해야 할 지 모를 때에는 ***(솔루션:01-vector-add-init-in-kernel-solution.cu)***을 참고하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0l_R_asfTsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8a483b8-fc57-445a-fcf1-3fa4aa8b8d8e"
      },
      "source": [
        "%%writefile 01-vector-add.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * Host function to initialize vector elements. This function\n",
        " * simply initializes each element to equal its index in the\n",
        " * vector.\n",
        " */\n",
        "\n",
        "__global__ void initWith(float num, float *a, int N)\n",
        "{\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        " \n",
        "  for(int i = index; i < N; i += stride)\n",
        "  {\n",
        "    a[i] = num;\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Device kernel stores into `result` the sum of each\n",
        " * same-indexed value of `a` and `b`.\n",
        " */\n",
        "\n",
        "__global__\n",
        "void addVectorsInto(float *result, float *a, float *b, int N)\n",
        "{\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < N; i += stride)\n",
        "  {\n",
        "    result[i] = a[i] + b[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Host function to confirm values in `vector`. This function\n",
        " * assumes all values are the same `target` value.\n",
        " */\n",
        "\n",
        "void checkElementsAre(float target, float *vector, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; i++)\n",
        "  {\n",
        "    if(vector[i] != target)\n",
        "    {\n",
        "      printf(\"FAIL: vector[%d] - %0.0f does not equal %0.0f\\n\", i, vector[i], target);\n",
        "      exit(1);\n",
        "    }\n",
        "  }\n",
        "  printf(\"Success! All values calculated correctly.\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const int N = 2<<24;\n",
        "  size_t size = N * sizeof(float);\n",
        "\n",
        "  float *a;\n",
        "  float *b;\n",
        "  float *c;\n",
        " \n",
        "  int deviceId;\n",
        "  cudaGetDevice(&deviceId);\n",
        "  cudaDeviceProp props;\n",
        "  cudaGetDeviceProperties(&props, deviceId);\n",
        "  int multiProcessorCount = props.multiProcessorCount;\n",
        "  int warpSize = props.warpSize;\n",
        "\n",
        "  cudaMallocManaged(&a, size);\n",
        "  cudaMallocManaged(&b, size);\n",
        "  cudaMallocManaged(&c, size);\n",
        "\n",
        "  size_t threadsPerBlock;\n",
        "  size_t numberOfBlocks;\n",
        "\n",
        "  /*\n",
        "   * nvprof should register performance changes when execution configuration\n",
        "   * is updated.\n",
        "   */\n",
        "\n",
        "  threadsPerBlock = warpSize*32;\n",
        "  numberOfBlocks = multiProcessorCount*32;\n",
        " \n",
        "  initWith<<<numberOfBlocks, threadsPerBlock>>>(3, a, N);\n",
        "  initWith<<<numberOfBlocks, threadsPerBlock>>>(4, b, N);\n",
        "  initWith<<<numberOfBlocks, threadsPerBlock>>>(0, c, N);\n",
        "\n",
        "  cudaError_t addVectorsErr;\n",
        "  cudaError_t asyncErr;\n",
        "\n",
        "  addVectorsInto<<<numberOfBlocks, threadsPerBlock>>>(c, a, b, N);\n",
        "\n",
        "  addVectorsErr = cudaGetLastError();\n",
        "  if(addVectorsErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(addVectorsErr));\n",
        "\n",
        "  asyncErr = cudaDeviceSynchronize();\n",
        "  if(asyncErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(asyncErr));\n",
        "\n",
        "  checkElementsAre(7, c, N);\n",
        "\n",
        "  cudaFree(a);\n",
        "  cudaFree(b);\n",
        "  cudaFree(c);\n",
        "}\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting 01-vector-add.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhuaffw1_RT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c2f2c1d-c1ea-47b2-d3d2-5696e44749c3"
      },
      "source": [
        "!nvcc -o initialize-in-kernel 01-vector-add.cu -run"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success! All values calculated correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GadlFwLQ_RT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac3a558-bc70-4410-be1c-d2f37e15d98d"
      },
      "source": [
        "!nvprof ./initialize-in-kernel"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==439== NVPROF is profiling process 439, command: ./initialize-in-kernel\n",
            "Success! All values calculated correctly.\n",
            "==439== Profiling application: ./initialize-in-kernel\n",
            "==439== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   97.11%  55.082ms         3  18.361ms  16.580ms  21.861ms  initWith(float, float*, int)\n",
            "                    2.89%  1.6421ms         1  1.6421ms  1.6421ms  1.6421ms  addVectorsInto(float*, float*, float*, int)\n",
            "      API calls:   80.19%  320.21ms         3  106.74ms  15.258us  320.13ms  cudaMallocManaged\n",
            "                   14.21%  56.721ms         1  56.721ms  56.721ms  56.721ms  cudaDeviceSynchronize\n",
            "                    5.40%  21.542ms         3  7.1808ms  6.3043ms  8.8109ms  cudaFree\n",
            "                    0.11%  424.89us         1  424.89us  424.89us  424.89us  cuDeviceTotalMem\n",
            "                    0.04%  157.39us       101  1.5580us     143ns  66.617us  cuDeviceGetAttribute\n",
            "                    0.03%  129.02us         1  129.02us  129.02us  129.02us  cudaGetDeviceProperties\n",
            "                    0.02%  65.922us         4  16.480us  4.9610us  46.950us  cudaLaunchKernel\n",
            "                    0.01%  27.899us         1  27.899us  27.899us  27.899us  cuDeviceGetName\n",
            "                    0.00%  6.8940us         1  6.8940us  6.8940us  6.8940us  cudaGetDevice\n",
            "                    0.00%  5.8600us         1  5.8600us  5.8600us  5.8600us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.9260us         3     642ns     236ns  1.3150us  cuDeviceGetCount\n",
            "                    0.00%  1.2180us         2     609ns     326ns     892ns  cuDeviceGet\n",
            "                    0.00%     350ns         1     350ns     350ns     350ns  cudaGetLastError\n",
            "                    0.00%     309ns         1     309ns     309ns     309ns  cuDeviceGetUuid\n",
            "\n",
            "==439== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "     768  170.67KB  4.0000KB  0.9961MB  128.0000MB  11.62762ms  Device To Host\n",
            "     682         -         -         -           -  53.83645ms  Gpu page fault groups\n",
            "Total CPU Page faults: 384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uXOmu2t_RT6"
      },
      "source": [
        "---\n",
        "## 비동기 메모리 프리패칭\n",
        "\n",
        "페이지 폴트와 호스트에서 디바이스로 또는 디바이스에서 호스트로의 메모리 전달인 요구시 메모리 마이그레이션으로 인한 오버헤드를 줄이는 강력한 기법을 **비동기 메모리 프리패칭(asynchronous memory prefetching)**이라고 합니다. 이 기법을 이용하면 애플리케이션이 메모리를 사용하려고 하기 전에 프로그래머가 UM을 임의의 CPU나 GPU로 마이그레이션할 수 있는데, 이는 비동기적으로 백그라운드에서 수행됩니다. 이를 통해 줄어든 페이지 폴트 및 요구시 마이그레이션만큼 GPU 커널과 CPU 함수의 성능이 향상됩니다.\n",
        "\n",
        "프리패칭은 데이터를 큰 덩어리로 마이그레이션하는 경향이 있어 요구시 마이그레이션보다 메모리 전달 빈도가 낮아집니다. 이는 접근할 데이터를 런타임 전에 알 수 있고, 데이터 접근 패턴이 산발적이지 않은 경우에 아주 적합합니다.\n",
        "\n",
        "CUDA는 `cudaMemPrefetchAsync` 함수를 이용하여 메모리에서 GPU/CPU로의 비동기적 프리패칭을 손쉽게 처리합니다. 아래 예제는 현재 활성화된 GPU로 데이터를 프리패치한 후, CPU로 프리패치하는 방법을 보여 줍니다.\n",
        "\n",
        "```cpp\n",
        "int deviceId;\n",
        "cudaGetDevice(&deviceId);                                         // The ID of the currently active GPU device.\n",
        "\n",
        "cudaMemPrefetchAsync(pointerToSomeUMData, size, deviceId);        // Prefetch to GPU device.\n",
        "cudaMemPrefetchAsync(pointerToSomeUMData, size, cudaCpuDeviceId); // Prefetch to host. `cudaCpuDeviceId` is a\n",
        "                                                                  // built-in CUDA variable.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvZ74TZnBxNi"
      },
      "source": [
        "### 실습: 메모리 프리패치하기\n",
        "\n",
        "지금쯤이면 여러분의 [01-vector-add.cu](../../../../../edit/tasks/task1/task/02_AC_UM_NVPROF-kr/01-vector-add/01-vector-add.cu) 프로그램은 두 개의 벡터를 더하여 세 번째 솔루션 벡터에 대입하는 CUDA 커널을 구동하며, 벡터들은 모두 `cudaMallocManaged`를 이용하여 할당되어 있을 것입니다. 그뿐만 아니라, 3 개의 벡터들은 모두 CUDA 커널에서 병렬로 초기화되어 있을 것입니다. 만약 여러분의 코드가 그렇게 되어 있지 않다면 [참조 코드](../../../../../edit/tasks/task1/task/02_AC_UM_NVPROF-kr/08-prefetch/01-vector-add-prefetch.cu)를 보시고 여러분의 코드를 수정하세요. \n",
        "\n",
        "여러분의 [`01-vector-add.cu`](../../../../../edit/tasks/task1/task/02_AC_UM_NVPROF-kr/01-vector-add/01-vector-add.cu)에서 `cudaMemPrefetchAsync`를 이용하고, 이 함수가 페이지 폴트와 메모리 마이그레이션에 미치는 영향을 세 가지 실험을 통해 알아 보세요. \n",
        "\n",
        "* 초기화된 벡터 중 하나를 호스트로 프리패치하면 어떤 일이 벌어지나요?\n",
        "* 초기화된 벡터 중 두 개를 호스트로 프리패치하면 어떤 일이 벌어지나요?\n",
        "* 초기화된 벡터 세 개 모두를 호스트로 프리패치하면 어떤 일이 벌어지나요?\n",
        "\n",
        "UM의 동작, 특히 페이지 폴트에 대한 가정과 커널 초기화 실행 시간에 미치는 영향에 대한 가정을 수립한 후, `nvprof`를 이용하여 실험을 하고 가정을 검증하세요. 어떻게 해야 할 지 모를 때에는 ***(솔루션:01-vector-add-prefetch-solution.cu)***을 참고하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDT-OsFNfYSw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac94778-6985-43cc-b9f6-15c76d9ae6f2"
      },
      "source": [
        "%%writefile 01-vector-add.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * Host function to initialize vector elements. This function\n",
        " * simply initializes each element to equal its index in the\n",
        " * vector.\n",
        " */\n",
        "\n",
        "void initWith(float num, float *a, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; ++i)\n",
        "  {\n",
        "    a[i] = num;\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Device kernel stores into `result` the sum of each\n",
        " * same-indexed value of `a` and `b`.\n",
        " */\n",
        "\n",
        "__global__\n",
        "void addVectorsInto(float *result, float *a, float *b, int N)\n",
        "{\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < N; i += stride)\n",
        "  {\n",
        "    result[i] = a[i] + b[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Host function to confirm values in `vector`. This function\n",
        " * assumes all values are the same `target` value.\n",
        " */\n",
        "\n",
        "void checkElementsAre(float target, float *vector, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; i++)\n",
        "  {\n",
        "    if(vector[i] != target)\n",
        "    {\n",
        "      printf(\"FAIL: vector[%d] - %0.0f does not equal %0.0f\\n\", i, vector[i], target);\n",
        "      exit(1);\n",
        "    }\n",
        "  }\n",
        "  printf(\"Success! All values calculated correctly.\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const int N = 2<<24;\n",
        "  size_t size = N * sizeof(float);\n",
        "\n",
        "  float *a;\n",
        "  float *b;\n",
        "  float *c;\n",
        " \n",
        "  int deviceId;\n",
        "  cudaGetDevice(&deviceId);\n",
        "  cudaDeviceProp props;\n",
        "  cudaGetDeviceProperties(&props, deviceId);\n",
        "\n",
        "  int multiProcessorCount = props.multiProcessorCount;\n",
        "  int warpSize = props.warpSize;\n",
        "\n",
        "  cudaMallocManaged(&a, size);\n",
        "  cudaMallocManaged(&b, size);\n",
        "  cudaMallocManaged(&c, size);\n",
        "\n",
        "  initWith(3, a, N);\n",
        "  initWith(4, b, N);\n",
        "  initWith(0, c, N);\n",
        " \n",
        "  cudaMemPrefetchAsync(a, size, deviceId);\n",
        "  cudaMemPrefetchAsync(b, size, deviceId);\n",
        "  cudaMemPrefetchAsync(c, size, deviceId);\n",
        " \n",
        "  size_t threadsPerBlock;\n",
        "  size_t numberOfBlocks;\n",
        "\n",
        "  /*\n",
        "   * nvprof should register performance changes when execution configuration\n",
        "   * is updated.\n",
        "   */\n",
        "\n",
        "  threadsPerBlock = warpSize*32;\n",
        "  numberOfBlocks = multiProcessorCount*32;\n",
        "\n",
        "  cudaError_t addVectorsErr;\n",
        "  cudaError_t asyncErr;\n",
        "\n",
        "  addVectorsInto<<<numberOfBlocks, threadsPerBlock>>>(c, a, b, N);\n",
        "\n",
        "  addVectorsErr = cudaGetLastError();\n",
        "  if(addVectorsErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(addVectorsErr));\n",
        "\n",
        "  asyncErr = cudaDeviceSynchronize();\n",
        "  if(asyncErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(asyncErr));\n",
        "\n",
        "  checkElementsAre(7, c, N);\n",
        "\n",
        "  cudaFree(a);\n",
        "  cudaFree(b);\n",
        "  cudaFree(c);\n",
        "}\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting 01-vector-add.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq_PCpCi_RT-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a0ccdfb-3dc0-4433-f039-c4fcc026d846"
      },
      "source": [
        "!nvcc -o prefetch-to-gpu 01-vector-add.cu -run"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success! All values calculated correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujHhJTwa_RUB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4636ee68-3d52-46d1-c81e-8019a553b9ad"
      },
      "source": [
        "!nvprof ./prefetch-to-gpu"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==490== NVPROF is profiling process 490, command: ./prefetch-to-gpu\n",
            "Success! All values calculated correctly.\n",
            "==490== Profiling application: ./prefetch-to-gpu\n",
            "==490== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  1.6351ms         1  1.6351ms  1.6351ms  1.6351ms  addVectorsInto(float*, float*, float*, int)\n",
            "      API calls:   84.68%  329.23ms         3  109.74ms  13.232us  329.16ms  cudaMallocManaged\n",
            "                    6.56%  25.491ms         1  25.491ms  25.491ms  25.491ms  cudaDeviceSynchronize\n",
            "                    5.47%  21.256ms         3  7.0855ms  6.3819ms  8.4144ms  cudaFree\n",
            "                    3.10%  12.059ms         3  4.0197ms  13.107us  11.905ms  cudaMemPrefetchAsync\n",
            "                    0.09%  348.15us         1  348.15us  348.15us  348.15us  cuDeviceTotalMem\n",
            "                    0.04%  154.11us         1  154.11us  154.11us  154.11us  cudaGetDeviceProperties\n",
            "                    0.04%  153.10us       101  1.5150us     135ns  65.247us  cuDeviceGetAttribute\n",
            "                    0.01%  49.027us         1  49.027us  49.027us  49.027us  cudaLaunchKernel\n",
            "                    0.01%  28.424us         1  28.424us  28.424us  28.424us  cuDeviceGetName\n",
            "                    0.00%  5.9250us         1  5.9250us  5.9250us  5.9250us  cuDeviceGetPCIBusId\n",
            "                    0.00%  5.5110us         1  5.5110us  5.5110us  5.5110us  cudaGetDevice\n",
            "                    0.00%  1.8050us         3     601ns     200ns  1.2790us  cuDeviceGetCount\n",
            "                    0.00%  1.2700us         2     635ns     196ns  1.0740us  cuDeviceGet\n",
            "                    0.00%     515ns         1     515ns     515ns     515ns  cudaGetLastError\n",
            "                    0.00%     259ns         1     259ns     259ns     259ns  cuDeviceGetUuid\n",
            "\n",
            "==490== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "     192  2.0000MB  2.0000MB  2.0000MB  384.0000MB  33.92397ms  Host To Device\n",
            "     768  170.67KB  4.0000KB  0.9961MB  128.0000MB  11.55091ms  Device To Host\n",
            "Total CPU Page faults: 1536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njvx92qI_RUE"
      },
      "source": [
        "### 실습: CPU로 메모리 프리패치하기 \n",
        "\n",
        "`addVectorIntoAdd` 커널이 잘 동작하는지 검증하는 함수를 위해 CPU로의 프리패칭을 추가하세요. `nvprog`를 이용하여 결과를 확인하기 전에 UM에 미치는 영향에 대한 가정을 수립하세요. 어떻게 해야 할 지 모를 때에는 ***(솔루션:02-vector-add-prefetch-solution-cpu-also.cu)***을 참고하세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc6kFZrcfcOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c268b71e-703d-4bf3-8a6f-f15be61c9fbf"
      },
      "source": [
        "%%writefile 01-vector-add.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        " * Host function to initialize vector elements. This function\n",
        " * simply initializes each element to equal its index in the\n",
        " * vector.\n",
        " */\n",
        "\n",
        "void initWith(float num, float *a, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; ++i)\n",
        "  {\n",
        "    a[i] = num;\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Device kernel stores into `result` the sum of each\n",
        " * same-indexed value of `a` and `b`.\n",
        " */\n",
        "\n",
        "__global__\n",
        "void addVectorsInto(float *result, float *a, float *b, int N)\n",
        "{\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "  for(int i = index; i < N; i += stride)\n",
        "  {\n",
        "    result[i] = a[i] + b[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "/*\n",
        " * Host function to confirm values in `vector`. This function\n",
        " * assumes all values are the same `target` value.\n",
        " */\n",
        "\n",
        "void checkElementsAre(float target, float *vector, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; i++)\n",
        "  {\n",
        "    if(vector[i] != target)\n",
        "    {\n",
        "      printf(\"FAIL: vector[%d] - %0.0f does not equal %0.0f\\n\", i, vector[i], target);\n",
        "      exit(1);\n",
        "    }\n",
        "  }\n",
        "  printf(\"Success! All values calculated correctly.\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const int N = 2<<24;\n",
        "  size_t size = N * sizeof(float);\n",
        "\n",
        "  float *a;\n",
        "  float *b;\n",
        "  float *c;\n",
        " \n",
        "  int deviceId;\n",
        "  cudaGetDevice(&deviceId);\n",
        "  cudaDeviceProp props;\n",
        "  cudaGetDeviceProperties(&props, deviceId);\n",
        "\n",
        "  int multiProcessorCount = props.multiProcessorCount;\n",
        "  int warpSize = props.warpSize;\n",
        "\n",
        "  cudaMallocManaged(&a, size);\n",
        "  cudaMallocManaged(&b, size);\n",
        "  cudaMallocManaged(&c, size);\n",
        "\n",
        "  initWith(3, a, N);\n",
        "  initWith(4, b, N);\n",
        "  initWith(0, c, N);\n",
        " \n",
        "  size_t threadsPerBlock;\n",
        "  size_t numberOfBlocks;\n",
        "\n",
        "  /*\n",
        "   * nvprof should register performance changes when execution configuration\n",
        "   * is updated.\n",
        "   */\n",
        "\n",
        "  threadsPerBlock = warpSize*32;\n",
        "  numberOfBlocks = multiProcessorCount*32;\n",
        "\n",
        "  cudaError_t addVectorsErr;\n",
        "  cudaError_t asyncErr;\n",
        "\n",
        "  addVectorsInto<<<numberOfBlocks, threadsPerBlock>>>(c, a, b, N);\n",
        "\n",
        "  addVectorsErr = cudaGetLastError();\n",
        "  if(addVectorsErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(addVectorsErr));\n",
        "\n",
        "  asyncErr = cudaDeviceSynchronize();\n",
        "  if(asyncErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(asyncErr));\n",
        "  cudaMemPrefetchAsync(c, size, cudaCpuDeviceId);\n",
        "\n",
        "  checkElementsAre(7, c, N);\n",
        "\n",
        "  cudaFree(a);\n",
        "  cudaFree(b);\n",
        "  cudaFree(c);\n",
        "}\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting 01-vector-add.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tjTExP__RUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e942849-4c8c-4503-971d-e3718419f65b"
      },
      "source": [
        "!nvcc -o prefetch-to-cpu 01-vector-add.cu -run"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success! All values calculated correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOBmgu76_RUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a28c4ed1-2484-4f8d-bd8e-9e8647312bad"
      },
      "source": [
        "!nvprof ./prefetch-to-cpu"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==541== NVPROF is profiling process 541, command: ./prefetch-to-cpu\n",
            "Success! All values calculated correctly.\n",
            "==541== Profiling application: ./prefetch-to-cpu\n",
            "==541== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  109.74ms         1  109.74ms  109.74ms  109.74ms  addVectorsInto(float*, float*, float*, int)\n",
            "      API calls:   68.32%  315.20ms         3  105.07ms  12.490us  315.14ms  cudaMallocManaged\n",
            "                   23.79%  109.75ms         1  109.75ms  109.75ms  109.75ms  cudaDeviceSynchronize\n",
            "                    5.37%  24.789ms         3  8.2629ms  6.6061ms  10.922ms  cudaFree\n",
            "                    2.35%  10.857ms         1  10.857ms  10.857ms  10.857ms  cudaMemPrefetchAsync\n",
            "                    0.08%  362.68us         1  362.68us  362.68us  362.68us  cuDeviceTotalMem\n",
            "                    0.03%  159.09us       101  1.5750us     137ns  67.150us  cuDeviceGetAttribute\n",
            "                    0.03%  124.74us         1  124.74us  124.74us  124.74us  cudaGetDeviceProperties\n",
            "                    0.01%  65.538us         1  65.538us  65.538us  65.538us  cudaLaunchKernel\n",
            "                    0.01%  29.513us         1  29.513us  29.513us  29.513us  cuDeviceGetName\n",
            "                    0.00%  6.5210us         2  3.2600us     730ns  5.7910us  cuDeviceGet\n",
            "                    0.00%  5.5570us         1  5.5570us  5.5570us  5.5570us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.7310us         1  2.7310us  2.7310us  2.7310us  cudaGetDevice\n",
            "                    0.00%  1.4490us         3     483ns     209ns     747ns  cuDeviceGetCount\n",
            "                    0.00%     568ns         1     568ns     568ns     568ns  cudaGetLastError\n",
            "                    0.00%     249ns         1     249ns     249ns     249ns  cuDeviceGetUuid\n",
            "\n",
            "==541== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "    4804  45.690KB  4.0000KB  984.00KB  214.3555MB  31.06419ms  Host To Device\n",
            "Total CPU Page faults: 1152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Geow9BAd_RUN"
      },
      "source": [
        "---\n",
        "## 요약\n",
        "\n",
        "이제 여러분은 아래와 같은 학습 목표를 달성하셨습니다.\n",
        "\n",
        "* **NVIDIA 커맨드라인 프로파일러(nvprof)**를 이용하여 가속화 애플리케이션의 성능 프로파일링하기\n",
        "* 실행 설정 최적화를 위한 **스트리밍 멀티프로세서**에 대한 체계적 이해\n",
        "* 페이지 폴트와 데이터 마이그레이션에 관련된 **통합 메모리**의 동작 이해\n",
        "* 페이지 폴트와 데이터 마이그레이션을 감소시켜 성능을 향상시키는 **비동기적 메모리 프리패칭** 사용\n",
        "* 반복적 개발 사이클을 적용하여 애플리케이션 가속화와 배치를 신속히 진행하기\n",
        "\n",
        "배운 내용을 숙지하고 애플리케이션의 반복적 가속화/최적화/배치에 대한 여러분의 능력을 향상시키기 위해 강좌의 마지막 실습을 수행하세요. 완료한 후에는 가급적 다음 세션의 *[고급 주제](https://courses.nvidia.com/api/jupyter/render_notebook/?url=https%3A%2F%2Fdeveloper.download.nvidia.com%2Ftraining%2Fcourses%2FC-AC-01-V1%2FAC_STREAMS_NVVP-kr%2FAC_STREAMS_NVVP-kr.ipynb&images_url=#%EA%B3%A0%EA%B8%89-%EC%A3%BC%EC%A0%9C)*의 내용도 적용해 보세요.\n",
        "\n",
        "---\n",
        "\n",
        "## 마지막 실습: 가속화 SAXPY 애플리케이션의 반복적 최적화\n",
        "\n",
        "기초적인 가속화 [SAXPY](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_1) 애플리케이션이 [여기](../../../../../edit/tasks/task1/task/02_AC_UM_NVPROF-kr/09-saxpy/01-saxpy.cu)에 준비되어 있습니다. 이 코드는 현재 몇 가지 버그가 있습니다. 이것들을 찾아 수정하고 실행한 뒤 `nvprof`을 이용하여 프로파일링하세요.\n",
        "\n",
        "다 되셨으면 `saxpy` 커널의 실행 시간을 기록하고 **반복적으로** 최적화를 진행하세요. 반복할 때마다 `nvprof`을 이용하여 코드 수정이 커널 성능과 UM 동작에 미치는 영향을 확인하세요.\n",
        "\n",
        "강좌에서 배운 기법을 적용해 보세요. 강좌에서 배운 기법을 교재에서만 찾기 보다는, 웹을 활용한 [검색을 통한 문제 해결(effortful retrieval)](http://sites.gsu.edu/scholarlyteaching/effortful-retrieval/)을 통해 학습한 내용을 더 잘 이해하실 수 있으실 것입니다.\n",
        "\n",
        "여러분의 목표는 올바른 saxpy 커널을 프로파일링하되, `N`을 바꾸지 않은 상태에서 *50us* 내에 실행을 완료하는 것입니다. 어떻게 해야 할 지 모를 때에는 ***(솔루션:02-saxpy-solution.cu)***을 참고하시고 자유롭게 컴파일하고 프로파일링 해보셔도 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPIWPPnBffnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25d4bef9-076a-4166-b1f9-8c6518c70ea8"
      },
      "source": [
        "%%writefile 01-saxpy.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define N 2048 * 2048 // Number of elements in each vector\n",
        "\n",
        "/*\n",
        " * Optimize this already-accelerated codebase. Work iteratively,\n",
        " * and use nvprof to support your work.\n",
        " *\n",
        " * Aim to profile `saxpy` (without modifying `N`) running under\n",
        " * 20us.\n",
        " *\n",
        " * Some bugs have been placed in this codebase for your edification.\n",
        " */\n",
        "\n",
        "__global__ void saxpy(int * a, int * b, int * c)\n",
        "{\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int stride = blockDim.x * gridDim.x;\n",
        " \n",
        "    for(int i = tid; i<N; i+=stride)\n",
        "        c[i] = 2 * a[i] + b[i];\n",
        "\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int *a, *b, *c;\n",
        " \n",
        "    int deviceId;\n",
        "    cudaGetDevice(&deviceId);    \n",
        "    cudaDeviceProp props;\n",
        "    cudaGetDeviceProperties(&props, deviceId); \n",
        "    int multiProcessorCount = props.multiProcessorCount;\n",
        "    int warpSize = props.warpSize;\n",
        " \n",
        "    int size = N * sizeof (int); // The total number of bytes per vector\n",
        "\n",
        "    cudaMallocManaged(&a, size);\n",
        "    cudaMallocManaged(&b, size);\n",
        "    cudaMallocManaged(&c, size);\n",
        "\n",
        "    // Initialize memory\n",
        "    for( int i = 0; i < N; ++i )\n",
        "    {\n",
        "        a[i] = 2;\n",
        "        b[i] = 1;\n",
        "        c[i] = 0;\n",
        "    }\n",
        "    cudaMemPrefetchAsync(a, size, deviceId);\n",
        "    cudaMemPrefetchAsync(b, size, deviceId);\n",
        "    cudaMemPrefetchAsync(c, size, deviceId); \n",
        "\n",
        "    int threads_per_block = warpSize*32;\n",
        "    int number_of_blocks = multiProcessorCount*32;\n",
        "\n",
        "    saxpy <<< number_of_blocks, threads_per_block >>> ( a, b, c );\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Print out the first and last 5 values of c for a quality check\n",
        "    for( int i = 0; i < 5; ++i )\n",
        "        printf(\"c[%d] = %d, \", i, c[i]);\n",
        "    printf (\"\\n\");\n",
        "    for( int i = N-5; i < N; ++i )\n",
        "        printf(\"c[%d] = %d, \", i, c[i]);\n",
        "    printf (\"\\n\");\n",
        "\n",
        "    cudaFree( a ); cudaFree( b ); cudaFree( c );\n",
        "}\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing 01-saxpy.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSw8KUsb_RUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6970688e-031b-463c-f3b2-7bd4c9d984b2"
      },
      "source": [
        "!nvcc -o saxpy 01-saxpy.cu -run"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c[0] = 5, c[1] = 5, c[2] = 5, c[3] = 5, c[4] = 5, \n",
            "c[4194299] = 5, c[4194300] = 5, c[4194301] = 5, c[4194302] = 5, c[4194303] = 5, \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFumLOe-_RUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad6702a0-9028-4820-bcc9-b44ea1485278"
      },
      "source": [
        "!nvprof ./saxpy"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==594== NVPROF is profiling process 594, command: ./saxpy\n",
            "c[0] = 5, c[1] = 5, c[2] = 5, c[3] = 5, c[4] = 5, \n",
            "c[4194299] = 5, c[4194300] = 5, c[4194301] = 5, c[4194302] = 5, c[4194303] = 5, \n",
            "==594== Profiling application: ./saxpy\n",
            "==594== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  195.80us         1  195.80us  195.80us  195.80us  saxpy(int*, int*, int*)\n",
            "      API calls:   97.37%  326.79ms         3  108.93ms  22.760us  326.73ms  cudaMallocManaged\n",
            "                    1.27%  4.2729ms         1  4.2729ms  4.2729ms  4.2729ms  cudaDeviceSynchronize\n",
            "                    0.76%  2.5516ms         3  850.53us  828.60us  881.85us  cudaFree\n",
            "                    0.37%  1.2370ms         3  412.33us  8.2510us  1.0793ms  cudaMemPrefetchAsync\n",
            "                    0.12%  393.70us         1  393.70us  393.70us  393.70us  cuDeviceTotalMem\n",
            "                    0.05%  152.69us       101  1.5110us     133ns  64.456us  cuDeviceGetAttribute\n",
            "                    0.04%  132.28us         1  132.28us  132.28us  132.28us  cudaGetDeviceProperties\n",
            "                    0.01%  49.321us         1  49.321us  49.321us  49.321us  cudaLaunchKernel\n",
            "                    0.01%  31.158us         1  31.158us  31.158us  31.158us  cuDeviceGetName\n",
            "                    0.00%  5.8620us         1  5.8620us  5.8620us  5.8620us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.9500us         1  2.9500us  2.9500us  2.9500us  cudaGetDevice\n",
            "                    0.00%  1.5820us         3     527ns     191ns     970ns  cuDeviceGetCount\n",
            "                    0.00%  1.2380us         2     619ns     224ns  1.0140us  cuDeviceGet\n",
            "                    0.00%     261ns         1     261ns     261ns     261ns  cuDeviceGetUuid\n",
            "\n",
            "==594== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      24  2.0000MB  2.0000MB  2.0000MB  48.00000MB  4.308480ms  Host To Device\n",
            "       4  32.000KB  4.0000KB  60.000KB  128.0000KB  17.37600us  Device To Host\n",
            "Total CPU Page faults: 146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoyauhcTp_FF"
      },
      "source": [
        "### HW6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA8m6j7XrYfl"
      },
      "source": [
        "아래에 있는 코드는 파동방정식의 코드입니다.(CPU only)\n",
        "\n",
        "해당 코드를 위에서 배운 지식들을 활용하여 최대한 가속화하십시오.\n",
        "\n",
        "그리고 위 코드를 가속화한 방법들에 대한 보고서를 자세히 작성하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuQmqNWMsM9y"
      },
      "source": [
        "***본인의 HW5 코드를 토대로 수정하시면 되고, 프로파일러를 토대로 하여 여러번***\n",
        "\n",
        "***반복하여 최대한 가속화를 진행해보시기 바랍니다.***\n",
        "\n",
        "코드와 보고서를 모두 블랙보드상에 10/13(화)까지 제출하시면 됩니다.\n",
        "\n",
        "파일제목양식 : 2020123456_홍길동_HW06"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyiqZbQkqB0Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aa83f82-c039-47a8-9dd5-5b887e577648"
      },
      "source": [
        "%%writefile hw6.cu\n",
        "#include<stdio.h>\n",
        "#include<math.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "#define PI 3.141592\n",
        "\n",
        "__global__ void Hyperbolic(float* U, float* U_new, int CFL, int N)\n",
        "{\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int stride = gridDim.x * blockDim.x;\n",
        "    for (int i = idx+1; i < N - 1; i+=stride)\n",
        "        U_new[i] = U[i] - CFL*(U[i] - U[i - 1]);\n",
        "}\n",
        "\n",
        "__global__ void Init(float* U,float* U_new, int N, int iter, float dx)\n",
        "{\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int stride = gridDim.x * blockDim.x;\n",
        "    for (int i = idx; i < N - 1; i+=stride)\n",
        "        U[i] = U_new[i] = 0;\n",
        "    for (int i = (int)((50) / dx)+idx; i < (int)((110.0 / dx) + 1); i+=stride)\n",
        "        U[i] = fabs(100.0 * (sin(PI * (i*dx - 50.0) / 60.0)));\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    float dx = 0.5;\n",
        "    float dt = 0.02;\n",
        "    float end_t = 6.0;\n",
        "    int L = 400;\n",
        "    int N = (int)((float)L / dx);\n",
        "    int iter = (int)(end_t / dt);\n",
        "    float CFL = 1.0;\n",
        "\n",
        "    float *U, *U_new;\n",
        "\n",
        "    const int size = N * sizeof(float);\n",
        "\n",
        "    int deviceId;\n",
        "    cudaGetDevice(&deviceId);\n",
        "    cudaDeviceProp props;\n",
        "    cudaGetDeviceProperties(&props, deviceId);\n",
        "    int multiProcessorCount = props.multiProcessorCount;\n",
        "    int warpSize = props.warpSize;\n",
        "\n",
        "    cudaMallocManaged(&U, size);\n",
        "    cudaMallocManaged(&U_new, size);\n",
        "  \n",
        "    size_t threads_per_block = warpSize*32;\n",
        "    size_t number_of_blocks = multiProcessorCount*32;\n",
        "\n",
        "    Init<<<number_of_blocks,threads_per_block>>>(U, U_new, N, iter, dx);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    for (int i = 0; i < N; i++)\n",
        "        printf(\"%.3f \", U[i]);\n",
        "    printf(\"\\n\\n\\n\");\n",
        "\n",
        "\tfor (int i = 0; i < iter; i++)\n",
        "\t{\n",
        "\t\tHyperbolic<<<number_of_blocks,threads_per_block>>>(U, U_new, CFL, N);\n",
        "    cudaDeviceSynchronize();\n",
        "\t\tfor (int j = 0; j < N; j++)\n",
        "\t\t\tU[j] = U_new[j];\n",
        "\t}\n",
        "\n",
        "\n",
        "\tfor (int i = 0; i < N; i++)\n",
        "\t\tprintf(\"%.3f \", U[i]);\n",
        "\tprintf(\"\\n\");\n",
        "\n",
        "\tcudaFree(U);\n",
        "\tcudaFree(U_new);\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting hw6.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jFreBp_p-nM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9162884f-8d14-4e37-900b-bd67880ba715"
      },
      "source": [
        "!nvcc -o hw6 hw6.cu -run"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 2.618 5.234 7.846 10.453 13.053 15.643 18.224 20.791 23.345 25.882 28.402 30.902 33.381 35.837 38.268 40.674 43.051 45.399 47.716 50.000 52.250 54.464 56.641 58.779 60.876 62.932 64.945 66.913 68.835 70.711 72.537 74.314 76.041 77.715 79.335 80.902 82.413 83.867 85.264 86.603 87.882 89.101 90.259 91.355 92.388 93.358 94.264 95.106 95.882 96.593 97.237 97.815 98.325 98.769 99.144 99.452 99.692 99.863 99.966 100.000 99.966 99.863 99.692 99.452 99.144 98.769 98.326 97.815 97.237 96.593 95.882 95.106 94.264 93.358 92.388 91.355 90.259 89.101 87.882 86.603 85.264 83.867 82.413 80.902 79.335 77.715 76.041 74.315 72.537 70.711 68.835 66.913 64.945 62.932 60.876 58.779 56.641 54.464 52.250 50.000 47.716 45.399 43.051 40.674 38.268 35.837 33.381 30.902 28.402 25.882 23.345 20.791 18.224 15.644 13.053 10.453 7.846 5.234 2.618 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 \n",
            "\n",
            "\n",
            "0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 2.618 5.234 7.846 10.453 13.053 15.643 18.224 20.791 23.345 25.882 28.402 30.902 33.381 35.837 38.268 40.674 43.051 45.399 47.716 50.000 52.250 54.464 56.641 58.779 60.876 62.932 64.945 66.913 68.835 70.711 72.537 74.314 76.041 77.715 79.335 80.902 82.413 83.867 85.264 86.603 87.882 89.101 90.259 91.355 92.388 93.358 94.264 95.106 95.882 96.593 97.237 97.815 98.325 98.769 99.144 99.452 99.692 99.863 99.966 100.000 99.966 99.863 99.692 99.452 99.144 98.769 98.326 97.815 97.237 96.593 95.882 95.106 94.264 93.358 92.388 91.355 90.259 89.101 87.882 86.603 85.264 83.867 82.413 80.902 79.335 77.715 76.041 74.315 72.537 70.711 68.835 66.913 64.945 62.932 60.876 58.779 56.641 54.464 52.250 50.000 47.716 45.399 43.051 40.674 38.268 35.837 33.381 30.902 28.402 25.882 23.345 20.791 18.224 15.644 13.053 10.453 7.846 5.234 2.618 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MpM6dVlfrDV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b286e7-d823-48ec-f2ee-16fdb1a5d3e6"
      },
      "source": [
        "!nvprof ./hw6"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==697== NVPROF is profiling process 697, command: ./hw6\n",
            "0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 2.618 5.234 7.846 10.453 13.053 15.643 18.224 20.791 23.345 25.882 28.402 30.902 33.381 35.837 38.268 40.674 43.051 45.399 47.716 50.000 52.250 54.464 56.641 58.779 60.876 62.932 64.945 66.913 68.835 70.711 72.537 74.314 76.041 77.715 79.335 80.902 82.413 83.867 85.264 86.603 87.882 89.101 90.259 91.355 92.388 93.358 94.264 95.106 95.882 96.593 97.237 97.815 98.325 98.769 99.144 99.452 99.692 99.863 99.966 100.000 99.966 99.863 99.692 99.452 99.144 98.769 98.326 97.815 97.237 96.593 95.882 95.106 94.264 93.358 92.388 91.355 90.259 89.101 87.882 86.603 85.264 83.867 82.413 80.902 79.335 77.715 76.041 74.315 72.537 70.711 68.835 66.913 64.945 62.932 60.876 58.779 56.641 54.464 52.250 50.000 47.716 45.399 43.051 40.674 38.268 35.837 33.381 30.902 28.402 25.882 23.345 20.791 18.224 15.644 13.053 10.453 7.846 5.234 2.618 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 \n",
            "\n",
            "\n",
            "0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 2.618 5.234 7.846 10.453 13.053 15.643 18.224 20.791 23.345 25.882 28.402 30.902 33.381 35.837 38.268 40.674 43.051 45.399 47.716 50.000 52.250 54.464 56.641 58.779 60.876 62.932 64.945 66.913 68.835 70.711 72.537 74.314 76.041 77.715 79.335 80.902 82.413 83.867 85.264 86.603 87.882 89.101 90.259 91.355 92.388 93.358 94.264 95.106 95.882 96.593 97.237 97.815 98.325 98.769 99.144 99.452 99.692 99.863 99.966 100.000 99.966 99.863 99.692 99.452 99.144 98.769 98.326 97.815 97.237 96.593 95.882 95.106 94.264 93.358 92.388 91.355 90.259 89.101 87.882 86.603 85.264 83.867 82.413 80.902 79.335 77.715 76.041 74.315 72.537 70.711 68.835 66.913 64.945 62.932 60.876 58.779 56.641 54.464 52.250 50.000 47.716 45.399 43.051 40.674 38.268 35.837 33.381 30.902 28.402 25.882 23.345 20.791 18.224 15.644 13.053 10.453 7.846 5.234 2.618 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 \n",
            "==697== Profiling application: ./hw6\n",
            "==697== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   97.90%  15.714ms       300  52.378us  31.677us  586.97us  Hyperbolic(float*, float*, int, int)\n",
            "                    2.10%  336.87us         1  336.87us  336.87us  336.87us  Init(float*, float*, int, int, float)\n",
            "      API calls:   93.71%  298.91ms         2  149.46ms  17.477us  298.89ms  cudaMallocManaged\n",
            "                    5.46%  17.417ms       301  57.864us  30.414us  592.06us  cudaDeviceSynchronize\n",
            "                    0.59%  1.8789ms       301  6.2420us  3.5020us  36.495us  cudaLaunchKernel\n",
            "                    0.11%  347.31us         1  347.31us  347.31us  347.31us  cuDeviceTotalMem\n",
            "                    0.04%  139.90us       101  1.3850us     139ns  59.469us  cuDeviceGetAttribute\n",
            "                    0.04%  126.02us         2  63.008us  31.681us  94.335us  cudaFree\n",
            "                    0.04%  113.78us         1  113.78us  113.78us  113.78us  cudaGetDeviceProperties\n",
            "                    0.01%  25.159us         1  25.159us  25.159us  25.159us  cuDeviceGetName\n",
            "                    0.00%  5.9790us         1  5.9790us  5.9790us  5.9790us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.9620us         1  2.9620us  2.9620us  2.9620us  cudaGetDevice\n",
            "                    0.00%  1.9260us         3     642ns     188ns  1.3320us  cuDeviceGetCount\n",
            "                    0.00%  1.2840us         2     642ns     202ns  1.0820us  cuDeviceGet\n",
            "                    0.00%     315ns         1     315ns     315ns     315ns  cuDeviceGetUuid\n",
            "\n",
            "==697== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      77  5.4541KB  4.0000KB  60.000KB  420.0000KB  244.8640us  Host To Device\n",
            "      79  6.1260KB  4.0000KB  60.000KB  484.0000KB  162.4000us  Device To Host\n",
            "     429         -         -         -           -  7.946240ms  Gpu page fault groups\n",
            "      11         -         -         -           -  4.085821ms  Page throttles\n",
            "      42  4.0000KB  4.0000KB  4.0000KB  168.0000KB           -  Memory thrashes\n",
            "       2  4.0000KB  4.0000KB  4.0000KB  8.000000KB           -  Remote mapping from device\n",
            "Total CPU Page faults: 65\n",
            "Total CPU thrashes: 42\n",
            "Total CPU throttles: 9\n",
            "Total remote mappings to CPU: 2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}