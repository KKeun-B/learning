#	파동방정식을 배운 지식들을 활용하여 최대한 가속화하시오

* 코드  

![image](https://user-images.githubusercontent.com/83944915/118296378-db1e3f80-b517-11eb-8b42-3feb45e76d51.png)
![image](https://user-images.githubusercontent.com/83944915/118296401-e40f1100-b517-11eb-9129-ba507157545d.png)
![image](https://user-images.githubusercontent.com/83944915/118296415-e7a29800-b517-11eb-8dde-6abedfdb71b3.png)
![image](https://user-images.githubusercontent.com/83944915/118296419-ea04f200-b517-11eb-915d-b6e354d4bb00.png)

* 고찰  

6주차 실험으로 CUDA C++ 통합 메모리와 nvprof를 이용한 가속화 어플리케이션에 대해 배우고 실습했다. 지난 주차에 실습한 것보다 더 가속화하기 위해 사용되는 방법으로 NVIDIA 커맨드라인 프로파일러를 통해 메모리의 비효율적인 작동을 효율적으로 만들기 위해 고안된 방법이다.  

기존의 CUDA 코드로 계산을 하면 CPU와 GPU간 메모리 전송이 오래 걸리고 사용하는 block, thread 개수의 최적화가 어렵기 때문에 NVIDIA 프로파일러를 통해 더욱 가속화된 결과를 얻을 수 있다. 프로파일을 이용한 실습 후 과제로 지난 주차에 CUDA로 가속화한 Wave equation C++코드를 프로파일을 이용해 더욱 가속시키는 것을 수행했다.  

가속화된 코드를 메모리 프로파일러로 더 가속화하기 위해서 사용되는 방법은 크게 세가지로 분류할 수 있다. 첫 번째로, SM, warp 개수를 이용한 블록, 스레드 수를 최적화하는 방법. 두 번째로, 페이지 폴트가 일어날 때 CPU => GPU로 GPU => CPU로 메모리 값을 옮기는데 이 때 일어나는 시간 소요를 줄이기 위해 커널에서 초기화하는 방법. 마지막으로, 메모리 프리패칭을 통해 메모리 전달 빈도를 낮춰 가속화하는 방법이 있다.
첫 번째 방법의 경우, 가속화에 쓰이는 스레드 수와 블록수가 일정 제한 속에서 클수록 계산 속도가 빨라지는 것을 알 수 있었다. 하나의 SM에 32개의 블록이 담길 수 있고 warp의 개수의 32 배수로 스레드 수를 설정하면 현재 내가 사용하고 있는 GPU를 가장 효율적으로 사용할 수 있다. 이는 계산속도의 증가로 이어진다.
두 번째 방법의 경우, CPU와 GPU에서 데이터를 사용할 때, 해당 데이터가 없으면 다른 Device 혹은 통합 메모리에서 가져오게 되는데 이때 걸리는 시간을 줄이기 위해 해당 데이터를 사용하는 Device에서 변수 초기화를 해줌으로써 필요한 데이터를 직접 넣어 Device간 데이터 이동이 필요 없도록 만들어 주는 방법이다.
세 번째 방법의 경우, 두 번째 방법과 달리 다른 Device에서 가져오는 메모리를 어느정도 가져올지 직접 선언해 줌으로써 비효율적인 데이터 이동을 방지하여 가속화하는 방법이다. 이를 통해 메모리 전달 빈도를 낮춰 더 효율적인 데이터 이동을 할 수 있다.
세 가지 방법을 실습해 보며 기존 코드로 진행할 때 보다 더 빠른 계산 속도를 보여주는 것을 확인했다.    

다만 첫 번째, 두 번째 방법의 경우 조금이라도 더 빠른 계산속도를 보여주었지만 세 번째 방법인 메모리 프리패치의 경우, 프리패치를 했을 때 계산속도가 빨라진 결과 도 얻었지만 프리패치를 적용한 경우와 적용하지 않은 경우 둘 다 비슷한 계산속도를 가지는 결과 역시 얻었다. 이를 통해 이 방법을 사용한다고 하여 무조건적인 빠른 계산속도를 보장하지 않는다는 것을 알게 되었다.
이번 주차 과제로써, 지난 주차에 가속화한 Wave equation 코드를 더 가속화하기 위해 첫 번째 방법과 세 번째 방법을 사용하였다. Global 함수를 통해 최대한 계산을 가속화한 상태에서 결과 값은 아래와 같이 나타났다.  
![image](https://user-images.githubusercontent.com/83944915/118296857-626bb300-b518-11eb-82da-82baf4b80867.png)  
<기본 코드 결과값>  
그 이후 SM, warp 개수를 이용해 블록, 스레드 수를 최적화하는 방법을 사용했는데 기본 코드 결과값보다 조금 더 빠른 결과를 얻은 것을 확인할 수 있었다.  
![image](https://user-images.githubusercontent.com/83944915/118297089-ac549900-b518-11eb-9b8f-a70162aa10e5.png)  
<SM, warp를 이용한 최적화 결과값>  
다음으로 메모리 프리패치를 두 단계에 나누어 진행해보았다. 첫 번째는, CPU에서 GPU로 프리패치를 한 것. 그 다음은, GPU에서 CPU로 프리패치 한 것이다.  
![image](https://user-images.githubusercontent.com/83944915/118297173-c42c1d00-b518-11eb-9fa1-23d0d6fbc27b.png)  
<CPU=>GPU 프리패치>  
![image](https://user-images.githubusercontent.com/83944915/118297195-caba9480-b518-11eb-9ac3-f2286a3d0da7.png)  
<GPU=>CPU 프리패치>  <br><br>
위와 같이, CPU 프리패치를 했을 때 SM, warp를 통한 최적화때보다 Host to Device의 total time이 약간 줄어든 결과를 얻었고 GPU 프리패치를 했을 때 Device to Host의 total time이 줄어든 결과를 얻게 되었다.
지금까지 NVIDIA 프로파일러를 이용하여 이전에 가속화한 wave equation을 더욱 가속화하는 실습을 해보았다. 이번 실험을 통해 메모리에서 나타나는 비효율성을 해결함으로써 계산 속도를 높일 수 있다는 것을 알게 되었고 이를 위해 세 가지 방법이 있다는 것 역시 알게 되었다. SM, warp 개수를 이용해 사용되는 스레드, 블록 수를 최적화하는 방법, 데이터 초기화를 사용하는 Device에서 해줌으로써 데이터 이동이 불필요하게 하는 방법, 메모리 패치를 통해 데이터 이동의 빈도 수를 줄여 효율적으로 만드는 방법이 앞서 말한 세 가지 방법이다. 이 중, 메모리 패치는 wave equation 코드처럼 가속화를 할 수도 있지만 무조건적인 빠른 속도를 보장하지 않는다는 것도 이번 실험을 통해 알게 되었다. 이번 실험을 통해 NVIDIA 프로파일러를 이용하면 병렬 계산식을 효율적으로 가속화하여 계산속도를 높일 수 있다는 결과를 얻게 되었다.
