# Timeline Visualization 포함 강의 요약

그동안 실습했던 벡터 합 가속화 코드를 이용해서 비동기식 스트리밍과 비주얼 프로파일링을 해보았다. 이를 통해 스트리밍을 사용했을 때 더 가속화가 되는 것과 가속화되기 전과 후의 과정을 가시화하여 직접 비교를 할 수 있었다. 

가시화를 한 코드와 기본 코드를 가시화하여 메모리 이동에 따른 시간 지연에 대해 중점적으로 학습했다. 프리 패치(prefetch) 여부, 여러 스트림 사용 여부, 커널에 직접 초기화 여부 등을 기준으로 비교하여 어떤 원리로 가속화가 되었는지, 걸린 시간은 얼마인지 시각적으로 알 수 있었다.  
![image](https://user-images.githubusercontent.com/83944915/118298347-52ed6980-b51a-11eb-9f1e-2dc2f26a9fc2.png)  
위의 사진처럼 가장 위에는 시간이 적혀 있고, 왼쪽의 항목에 따라 메모리 이동과 실행되는 위치를 시각적으로 알 수 있다. 첫 번째로, 메모리 프리 패치 여부에 따라 비교를 해보았다. CPU에서 초기화되면 GPU 함수에서 해당 값을 사용하기 위해 CPU에서 GPU로 계산이 끝난 이후 GPU에서 CPU로 메모리 이동이 발생한다. 해당 메모리 이동은 커널이 실행될 때 메모리가 필요한 만큼만 조금씩 옮기기 때문에 비효율적이며 시간이 오래 걸린다. 이를 해결하기 위해 CPU에 선언된 초기 값을 미리 GPU 메모리로 이동시켜주면 조금 더 빠른 속도로 계산이 되는 것을 알 수 있다. 벡터 합 커널을 실행했을 때 메모리 프리 패칭을 하지 않은 경우 800ms의 시간이 걸렸지만 프리 패칭을 한 경우 740ms의 시간이 걸린 것을 확인할 수 있었다. 마찬가지로 계산이 끝난 이후, GPU에서 CPU로 메모리 프리 패칭을 하게 되면 하지 않을 때 보다 더 빠른 계산 속도를 가지는 것을 확인했다. 두 번째로, 초기 값 선언을 커널에서 했는지 여부에 따라 비교해보았다. 앞에서 다룬 내용은 메모리를 미리 선언하여 메모리 이동의 효율을 높임으로써 가속화시키는 방법이었다면 이 방법은 CPU에서 GPU로 메모리 이동이 불필요하도록 GPU 커널에서 초기 값을 선언하는 방식이다. 메모리 이동이 없으니 메모리 이동에 따른 시간 지연이 없어 앞의 방법보다 더 효율적인 방법이다. CPU에서 초기화 후 프리 패치를 한 경우 900ms 정도의 시간이 걸렸지만 GPU에서 초기 값을 선언하면 430ms 정도의 시간이 걸리는 것을 확인할 수 있었다. 이를 통해 메모리 이동 여부에 따라 절반정도의 시간을 단축하는 결과를 얻게 되었다.  
![image](https://user-images.githubusercontent.com/83944915/118298401-60a2ef00-b51a-11eb-9f9c-2745442367e8.png)  
세번째로, 여러 스트림을 사용했을 때 어떻게 작동하는지를 알아보았다. 위의 그림과 같이 GPU함수가 구동할 때는 하나의 스트림에서 순차적으로 작동하는데 다른 스트림 간에는 순차적으로 실행되지 않고 겹쳐서 실행될 수 있다. 기본적으로 이 스트림을 설정해주지 않는다면 하나의 Stream에서 순차적으로 하나씩 명령어를 처리하지만, 스트림을 설정해주면 여러 개의 스트림을 이용해 겹쳐서 실행시켜 계산 시간을 단축시킬 수 있다. 또한 Default Stream은 여러 Stream의 경계를 차단해주는 경계와 같은 역할도 할 수 있다.

마지막으로, 지금까지 실습해 온 것을 통해 N-body simulator를 최적화하는 것을 했다. 이는 NVIDIA 코스 환경이 필수적이기 때문에 직접 실습해보지는 못했지만 조교님께서 하시는 것을 보며 그동안 실습해왔던 global 함수선언, for문 stride(block과 grid 수를 이용함)로 가속화하기, 메모리 패치, CUDA 메모리 할당 및 해제, CUDA 함수 동기화 등을 복습하는 시간을 가졌다. 위의 나열된 과정들을 통해 GPU함수를 이용하면 기존의 CPU함수를 사용하는 것보다 훨씬 더 빠른 속도를 갖는 결과를 얻을 수 있음을 알게 되었다.

지난 주차 까지는 GPU를 이용해 병렬 연산하여 가속화하려면 어떤 방법들을 써야 하는지에 대해서 배웠고 이번 주차에서는 이런 방법들을 직접 시각화하여 쉽게 비교할 수 있는 방법들에 대해 배웠다. 이번 주차의 시각화를 알기 전까지는 대략적으로 “병렬연산을 하니까 당연히 빠르겠지” 라고만 생각하였고 실행 결과가 빠르게 나오는 것만 확인을 했지 실제로 어떻게 작동하는지는 전혀 알 수 없었다. 그동안 실습했던 벡터 합 코드를 시각화해서 작동하는 시간과 Device 및 메모리 이동을 직접 보니 어떤 과정으로 메모리가 이동하고 GPU 함수가 작동하는지 잘 이해할 수 있었다. 특히 결과 값으로만 표현되었던 계산 시간이 시각화를 통해 어느 명령문에서 얼만큼의 시간이 걸렸고 데이터 이동량은 어느 정도인지 등의 세부 정보를 알 수 있어 CUDA를 이용한 가속화에 대해 조금 더 깊게 이해할 수 있게 된 시간을 가진 것 같다. 

*	지금까지 배운 이론 요약
>* CPU 함수 호출과 GPU 커널 구동을 포함한 코드로 작성 및 컴파일, 실행하기(global 함수 선언)
>*	실행 설정을 이용해 병렬 스레드 계층구조 제어하기
>*	블록, 스레드 개수 최적화하기(Sm이용)
>*	반복문을 GPU에서 병렬로 실행하여 가속화하기(block, thread 개수, Idx, stride이용)
>*	커널 동기화하기(cudaDeviceSynchronize)
>*	통합 메모리의 할당 및 해제(cudaMallocManaged, cudaFree)
>*	메모리 프리 패칭(cudaMemPrefetchAsync)

*	오늘 배운 이론 요약  
>*	NVIDIA 비주얼 프로파일러(nvvp)를 이용한 가속화 코드의 타임라인을 시각화하기
>*	CUDA 스트림을 이용하여 커널들을 동시에 실행하여 가속화하기
>*	수동 메모리 할당을 통해 비동기로 효율적인 데이터 옮기기
